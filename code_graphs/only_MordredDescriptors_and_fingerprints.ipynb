{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIF360 Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main source: https://www.kaggle.com/code/rmonge/predicting-molecule-properties-based-on-its-smiles/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time as time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import networkx as nx\n",
    "from torch.nn import Linear, LeakyReLU\n",
    "from torch_geometric.nn import global_mean_pool, GATConv, BatchNorm, GraphNorm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "device: cuda\n",
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132820, 21)\n",
      "(132820, 985)\n",
      "(132820, 2048)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/smiles_and_targets.csv\")\n",
    "print(np.shape(df))\n",
    "\n",
    "mol_descriptor = np.load(\"../data/Mordred_mol_descriptors.npy\")\n",
    "print(mol_descriptor.shape)\n",
    "\n",
    "mol_fingerprints = np.load(\"../data/mol_morgan_fingerprints.npy\")\n",
    "print(mol_fingerprints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from utility_functions import get_data_split_indices\n",
    "\n",
    "def create_scale_and_split_dataset(features:np.ndarray, targets:np.ndarray, val_share, test_share, batch_size):\n",
    "    \n",
    "    train_indices, val_indices, test_indices = get_data_split_indices(features.shape[0], val_share, test_share)\n",
    "    \n",
    "    X_train, y_train = features[train_indices], targets[train_indices]\n",
    "    X_val, y_val = features[val_indices], targets[val_indices]\n",
    "    X_test, y_test = features[test_indices], targets[test_indices]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    scaler_targets = StandardScaler()\n",
    "    y_train = scaler_targets.fit_transform(y_train)\n",
    "    y_val = scaler_targets.transform(y_val)\n",
    "    y_test = scaler_targets.transform(y_test)\n",
    "    \n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32, device=device),\n",
    "                               torch.tensor(y_train, dtype=torch.float32, device=device))\n",
    "    val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32, device=device),\n",
    "                            torch.tensor(y_val, dtype=torch.float32, device=device))\n",
    "    test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32, device=device),\n",
    "                                torch.tensor(y_test, dtype=torch.float32, device=device))\n",
    "\n",
    "    \n",
    "    return train_data, val_data, test_data, scaler_targets\n",
    "\n",
    "def create_data_loaders(train_data, val_data, test_data, batch_size):\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Loading data...\n",
      "...Data loading done...\n"
     ]
    }
   ],
   "source": [
    "print(\"...Loading data...\")\n",
    "properties_names = ['A', 'B', 'C', 'mu', 'alfa', 'homo', 'lumo', 'gap', 'RÂ²', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "x_smiles = df.smiles.values\n",
    "y = df.loc[:, properties_names].values\n",
    "\n",
    "features = np.concatenate((mol_descriptor, mol_fingerprints), axis=1)\n",
    "\n",
    "train_data, val_data, test_data, scaler_targets = create_scale_and_split_dataset(features, y, 0.15, 0.2, 64)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_data, val_data, test_data, 64)\n",
    "print(\"...Data loading done...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense network "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for all targets at once"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, feature_dim, target_dim):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        \n",
    "        self.input_norm = BatchNorm(feature_dim)\n",
    "        self.lin1 = Linear(feature_dim, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 512)\n",
    "        self.lin3 = Linear(512, target_dim)\n",
    "\n",
    "    def forward(self, x): \n",
    "                \n",
    "        x = self.input_norm(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.lin3(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 3645377\n",
      "Trainable parameters: 3645377\n",
      "\n",
      "...Starting training...\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.12303 | Validation Loss: 0.10497\n",
      "Validation R2: [0.77897328 0.89232372 0.91811492 0.59263023 0.9661426  0.80712823\n",
      " 0.9359219  0.8943081  0.9425438  0.99059181 0.99307779 0.99358267\n",
      " 0.99331053 0.99351325 0.97816684]\n",
      "Validation loss: 0.08534403396949458\n",
      "Epoch: 02 | Train Loss: 0.10173 | Validation Loss: 0.09752\n",
      "Epoch: 03 | Train Loss: 0.09633 | Validation Loss: 0.08994\n",
      "Epoch: 04 | Train Loss: 0.09243 | Validation Loss: 0.09116\n",
      "Epoch: 05 | Train Loss: 0.08815 | Validation Loss: 0.08348\n",
      "Epoch: 06 | Train Loss: 0.08546 | Validation Loss: 0.08370\n",
      "Epoch: 07 | Train Loss: 0.08314 | Validation Loss: 0.07940\n",
      "Epoch: 08 | Train Loss: 0.08058 | Validation Loss: 0.07881\n",
      "Epoch: 09 | Train Loss: 0.07857 | Validation Loss: 0.07780\n",
      "Epoch: 10 | Train Loss: 0.07707 | Validation Loss: 0.07531\n",
      "Validation R2: [0.82941789 0.91282307 0.93027837 0.6646775  0.98004264 0.88289584\n",
      " 0.95743863 0.94021728 0.95416007 0.99419711 0.99643939 0.99643037\n",
      " 0.99641566 0.99641249 0.98412085]\n",
      "Validation loss: 0.062398207203771636\n",
      "Epoch: 11 | Train Loss: 0.07594 | Validation Loss: 0.07562\n",
      "Epoch: 12 | Train Loss: 0.07430 | Validation Loss: 0.07640\n",
      "Epoch: 13 | Train Loss: 0.07299 | Validation Loss: 0.07182\n",
      "Epoch: 14 | Train Loss: 0.07166 | Validation Loss: 0.07040\n",
      "Epoch: 15 | Train Loss: 0.07042 | Validation Loss: 0.07485\n",
      "Epoch: 16 | Train Loss: 0.06961 | Validation Loss: 0.06977\n",
      "Epoch: 17 | Train Loss: 0.06842 | Validation Loss: 0.06980\n",
      "Epoch: 18 | Train Loss: 0.06797 | Validation Loss: 0.06828\n",
      "Epoch: 19 | Train Loss: 0.06685 | Validation Loss: 0.06738\n",
      "Epoch: 20 | Train Loss: 0.06594 | Validation Loss: 0.06735\n",
      "Validation R2: [0.85469225 0.92767578 0.9422841  0.6679202  0.98417691 0.90093671\n",
      " 0.96673421 0.95144452 0.96304765 0.99445654 0.99698303 0.99698616\n",
      " 0.99698095 0.99698184 0.98821074]\n",
      "Validation loss: 0.05529124224379372\n",
      "Epoch: 21 | Train Loss: 0.06516 | Validation Loss: 0.06672\n",
      "Epoch: 22 | Train Loss: 0.06458 | Validation Loss: 0.06801\n",
      "Epoch: 23 | Train Loss: 0.06399 | Validation Loss: 0.06593\n",
      "Epoch: 24 | Train Loss: 0.06349 | Validation Loss: 0.06566\n",
      "Epoch: 25 | Train Loss: 0.06313 | Validation Loss: 0.06446\n",
      "Epoch: 26 | Train Loss: 0.06230 | Validation Loss: 0.06418\n",
      "Epoch: 27 | Train Loss: 0.06174 | Validation Loss: 0.06423\n",
      "Epoch: 28 | Train Loss: 0.06151 | Validation Loss: 0.06401\n",
      "Epoch: 29 | Train Loss: 0.06136 | Validation Loss: 0.06401\n",
      "Epoch: 30 | Train Loss: 0.06088 | Validation Loss: 0.06395\n",
      "...Training done...\n",
      "...Calculating final results...\n",
      "====================================================\n",
      "Final training R2: [0.88325106 0.93415563 0.94913321 0.73315839 0.98637244 0.91682109\n",
      " 0.97227444 0.958985   0.96384616 0.99543542 0.9978198  0.99782194\n",
      " 0.99782314 0.99782278 0.98994156]\n",
      "Average final training R2:  0.9516441368385322\n",
      "Final training loss: 0.04591820021335994\n",
      "Final validation R2: [0.86570908 0.92993483 0.94361619 0.69733046 0.98593901 0.90697181\n",
      " 0.96958147 0.95512856 0.96115657 0.99553117 0.99777793 0.99777868\n",
      " 0.99778226 0.99778054 0.99026005]\n",
      "Average validation test R2:  0.9461519063066606\n",
      "Final validation loss: 0.05142589569844019\n",
      "Final test R2: [0.86570908 0.92993483 0.94361619 0.69733046 0.98593901 0.90697181\n",
      " 0.96958147 0.95512856 0.96115657 0.99553117 0.99777793 0.99777868\n",
      " 0.99778226 0.99778054 0.99026005]\n",
      "Average final test R2:  0.9461519063066606\n",
      "Final test loss: 0.05142589569844019\n"
     ]
    }
   ],
   "source": [
    "from utility_functions import get_num_parameters\n",
    "\n",
    "feature_dim = train_data[:][0].shape[1]\n",
    "target_dim = train_data[:][1].shape[1]\n",
    "\n",
    "model = GNN(hidden_channels=1024, feature_dim=feature_dim, target_dim=target_dim).to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# Decay for learning rate\n",
    "decayRate = 0.9\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "train_params, tot_params = get_num_parameters(model)\n",
    "print(f\"Total number of parameters: {tot_params}\")\n",
    "print(f\"Trainable parameters: {train_params}\")\n",
    "\n",
    "def train(batch):\n",
    "      features = batch[:][0]\n",
    "      targets = batch[:][1]\n",
    "      \n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(features).to(device)  # Perform a single forward pass.\n",
    "\n",
    "      loss = criterion(out, targets) \n",
    "\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      \n",
    "      return loss\n",
    "\n",
    "def test(data):\n",
    "      for i, batch in enumerate(data):\n",
    "            features = batch[:][0]\n",
    "            targets = batch[:][1].cpu()\n",
    "            \n",
    "            model.eval()\n",
    "            out = model(features).cpu()\n",
    "            \n",
    "            # Caculate R2 for each target\n",
    "            for target_idx in range(target_dim):\n",
    "                  if target_idx != 0:\n",
    "                        r2_score_var = np.vstack((r2_score_var, r2_score(targets[:,target_idx].detach().numpy(), \n",
    "                                                          out[:,target_idx].detach().numpy())))\n",
    "                  else:\n",
    "                        r2_score_var = np.array([r2_score(targets[:,target_idx].detach().numpy(),\n",
    "                                                          out[:,target_idx].detach().numpy())])        \n",
    "            all_r2 = np.hstack((all_r2, r2_score_var)) if i != 0 else r2_score_var\n",
    "                  \n",
    "            loss = float(criterion(out, targets).detach().numpy())\n",
    "            all_loss = np.hstack((all_loss, loss)) if i != 0 else np.array(loss)\n",
    "\n",
    "      average_test_r2 = np.mean(all_r2, axis=1)\n",
    "      average_test_loss = np.mean(all_loss)\n",
    "      \n",
    "      return average_test_r2, average_test_loss\n",
    "\n",
    "# Vectors to append accuracy to:\n",
    "train_r2 = []\n",
    "train_loss = []\n",
    "test_r2 = []\n",
    "test_loss = []\n",
    "val_r2 = []\n",
    "val_loss = []\n",
    "\n",
    "n_epochs = 30\n",
    "print_every_N_epochs = True\n",
    "N = 10 # print R2 every N epochs\n",
    "\n",
    "epoch_times = []\n",
    "train_times = []\n",
    "test_times = []\n",
    "print()\n",
    "print(\"...Starting training...\")\n",
    "print(\"Device used:\", device)\n",
    "\n",
    "for epoch in np.arange(1, n_epochs+1):\n",
    "      epoch_start = time.time()\n",
    "      losses = []\n",
    "      train_start = time.time()\n",
    "      for data in train_loader:\n",
    "            loss = train(data)\n",
    "            losses.append(loss.cpu().detach().numpy())  \n",
    "      # Compute validation loss\n",
    "      with torch.no_grad():\n",
    "            val_losses = []\n",
    "            for batch in val_loader:\n",
    "                  features = batch[:][0]\n",
    "                  targets = batch[:][1]\n",
    "                  out = model(features)\n",
    "                  val_losses.append(criterion(out, targets).cpu().detach().numpy())\n",
    "      print(f\"Epoch: {epoch:02d} | Train Loss: {np.mean(losses):.5f} | Validation Loss: {np.mean(val_losses):.5f}\")\n",
    "      train_end = time.time()\n",
    "      train_times.append(train_end - train_start)\n",
    "      \n",
    "      lr_scheduler.step() # Decay to learning rate\n",
    "      \n",
    "      if print_every_N_epochs and (epoch % N == 0 or epoch == 1) and epoch != n_epochs:\n",
    "            test_start = time.time()\n",
    "                \n",
    "            r2_temp_val, loss_temp_val = test(test_loader)\n",
    "            val_r2.append(r2_temp_val)\n",
    "            val_loss.append(loss_temp_val)\n",
    "            \n",
    "            print(f'Validation R2: {r2_temp_val}')\n",
    "            print(f\"Validation loss: {loss_temp_val}\")\n",
    "            test_end = time.time()\n",
    "            test_times.append(test_end - test_start)\n",
    "            \n",
    "      if epoch == n_epochs:         # calculate results of training: test on all data\n",
    "            print(\"...Training done...\")\n",
    "            print(\"...Calculating final results...\")\n",
    "            test_start = time.time()\n",
    "            r2_temp_train, loss_temp_train = test(train_loader) \n",
    "            train_r2.append(r2_temp_train)\n",
    "            train_loss.append(loss_temp_train)\n",
    "            \n",
    "            r2_temp_val, loss_temp_val = test(test_loader)\n",
    "            val_r2.append(r2_temp_val)\n",
    "            val_loss.append(loss_temp_val)\n",
    "            \n",
    "            r2_temp_test, loss_temp_test = test(test_loader)\n",
    "            test_r2.append(r2_temp_test)\n",
    "            test_loss.append(loss_temp_test)\n",
    "\n",
    "            print(\"====================================================\")\n",
    "            print(\"Final training R2:\", train_r2[-1])\n",
    "            print(\"Average final training R2: \", np.mean(train_r2[-1]))\n",
    "            print(\"Final training loss:\", train_loss[-1])\n",
    "            \n",
    "            print(\"Final validation R2:\", val_r2[-1])\n",
    "            print(\"Average validation test R2: \", np.mean(val_r2[-1]))\n",
    "            print(\"Final validation loss:\", val_loss[-1])\n",
    "\n",
    "            print(\"Final test R2:\", test_r2[-1])\n",
    "            print(\"Average final test R2: \", np.mean(test_r2[-1]))\n",
    "            print(\"Final test loss:\", test_loss[-1])\n",
    "            \n",
    "            test_end = time.time()\n",
    "            test_times.append(test_end - test_start)\n",
    "            \n",
    "      epoch_end = time.time()\n",
    "      epoch_times.append(epoch_end - epoch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n",
      "\n",
      "Total number of epochs: 30\n",
      "Total training time: 1.45 minutes\n",
      "Total time in training: 1.30 minutes\n",
      "Total time in testing: 0.15 minutes\n",
      "\n",
      "Average epoch time: 2.9 seconds\n",
      "Average time in training: 2.6 seconds\n",
      "Average time in testing: 2.3 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Device used:\", device)\n",
    "print()\n",
    "print(f\"Total number of epochs: {len(epoch_times)}\")\n",
    "print(f\"Total training time: {np.sum(epoch_times)/60:.2f} minutes\")\n",
    "print(f\"Total time in training: {np.sum(train_times)/60:.2f} minutes\")\n",
    "print(f\"Total time in testing: {np.sum(test_times)/60:.2f} minutes\")\n",
    "print()\n",
    "print(f\"Average epoch time: {np.mean(epoch_times):.1f} seconds\")\n",
    "print(f\"Average time in training: {np.mean(train_times):.1f} seconds\")\n",
    "print(f\"Average time in testing: {np.mean(test_times):.1f} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for just one target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target index: 0\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.20331 | Validation Loss: 0.16931\n",
      "Epoch: 02 | Train Loss: 0.13334 | Validation Loss: 0.13731\n",
      "Epoch: 03 | Train Loss: 0.11218 | Validation Loss: 0.12130\n",
      "Epoch: 04 | Train Loss: 0.09657 | Validation Loss: 0.10917\n",
      "Epoch: 05 | Train Loss: 0.08596 | Validation Loss: 0.10260\n",
      "Epoch: 06 | Train Loss: 0.07844 | Validation Loss: 0.10326\n",
      "Epoch: 07 | Train Loss: 0.07271 | Validation Loss: 0.10409\n",
      "Epoch: 08 | Train Loss: 0.06706 | Validation Loss: 0.09729\n",
      "Epoch: 09 | Train Loss: 0.06232 | Validation Loss: 0.09121\n",
      "Epoch: 10 | Train Loss: 0.05829 | Validation Loss: 0.08852\n",
      "====================================================\n",
      "Final training R2: 0.8930999648095416\n",
      "Average final training R2:  0.8930999648095416\n",
      "Final training loss: 0.10087261825601113\n",
      "\n",
      "Final validation R2: 0.8405620029856536\n",
      "Average validation test R2:  0.8405620029856536\n",
      "Final validation loss: 0.1506244971936282\n",
      "\n",
      "Final test R2: 0.8405620029856536\n",
      "Average final test R2:  0.8405620029856536\n",
      "Final test loss: 0.1506244971936282\n",
      "====================================================\n",
      "Target index: 1\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.11820 | Validation Loss: 0.08578\n",
      "Epoch: 02 | Train Loss: 0.07830 | Validation Loss: 0.08795\n",
      "Epoch: 03 | Train Loss: 0.06573 | Validation Loss: 0.06872\n",
      "Epoch: 04 | Train Loss: 0.05848 | Validation Loss: 0.06213\n",
      "Epoch: 05 | Train Loss: 0.05255 | Validation Loss: 0.05890\n",
      "Epoch: 06 | Train Loss: 0.04877 | Validation Loss: 0.05359\n",
      "Epoch: 07 | Train Loss: 0.04530 | Validation Loss: 0.05373\n",
      "Epoch: 08 | Train Loss: 0.04278 | Validation Loss: 0.05367\n",
      "Epoch: 09 | Train Loss: 0.04027 | Validation Loss: 0.05175\n",
      "Epoch: 10 | Train Loss: 0.03851 | Validation Loss: 0.04863\n",
      "====================================================\n",
      "Final training R2: 0.9576054984833967\n",
      "Average final training R2:  0.9576054984833967\n",
      "Final training loss: 0.039682114702560355\n",
      "\n",
      "Final validation R2: 0.9353103136648205\n",
      "Average validation test R2:  0.9353103136648205\n",
      "Final validation loss: 0.060880919121420726\n",
      "\n",
      "Final test R2: 0.9353103136648205\n",
      "Average final test R2:  0.9353103136648205\n",
      "Final test loss: 0.060880919121420726\n",
      "====================================================\n",
      "Target index: 2\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.09324 | Validation Loss: 0.06492\n",
      "Epoch: 02 | Train Loss: 0.06018 | Validation Loss: 0.06970\n",
      "Epoch: 03 | Train Loss: 0.05212 | Validation Loss: 0.05335\n",
      "Epoch: 04 | Train Loss: 0.04744 | Validation Loss: 0.05046\n",
      "Epoch: 05 | Train Loss: 0.04389 | Validation Loss: 0.04830\n",
      "Epoch: 06 | Train Loss: 0.04105 | Validation Loss: 0.04378\n",
      "Epoch: 07 | Train Loss: 0.03906 | Validation Loss: 0.04236\n",
      "Epoch: 08 | Train Loss: 0.03656 | Validation Loss: 0.04259\n",
      "Epoch: 09 | Train Loss: 0.03486 | Validation Loss: 0.05404\n",
      "Epoch: 10 | Train Loss: 0.03431 | Validation Loss: 0.03964\n",
      "====================================================\n",
      "Final training R2: 0.9641637836211817\n",
      "Average final training R2:  0.9641637836211817\n",
      "Final training loss: 0.03323755251399736\n",
      "\n",
      "Final validation R2: 0.9470331143503583\n",
      "Average validation test R2:  0.9470331143503583\n",
      "Final validation loss: 0.05011537092146822\n",
      "\n",
      "Final test R2: 0.9470331143503583\n",
      "Average final test R2:  0.9470331143503583\n",
      "Final test loss: 0.05011537092146822\n",
      "====================================================\n",
      "Target index: 3\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.38309 | Validation Loss: 0.32738\n",
      "Epoch: 02 | Train Loss: 0.28608 | Validation Loss: 0.29927\n",
      "Epoch: 03 | Train Loss: 0.24375 | Validation Loss: 0.27653\n",
      "Epoch: 04 | Train Loss: 0.20981 | Validation Loss: 0.26171\n",
      "Epoch: 05 | Train Loss: 0.18478 | Validation Loss: 0.25502\n",
      "Epoch: 06 | Train Loss: 0.16255 | Validation Loss: 0.24778\n",
      "Epoch: 07 | Train Loss: 0.14396 | Validation Loss: 0.25004\n",
      "Epoch: 08 | Train Loss: 0.12881 | Validation Loss: 0.24254\n",
      "Epoch: 09 | Train Loss: 0.11588 | Validation Loss: 0.24171\n",
      "Epoch: 10 | Train Loss: 0.10486 | Validation Loss: 0.23605\n",
      "====================================================\n",
      "Final training R2: 0.755652322499433\n",
      "Average final training R2:  0.755652322499433\n",
      "Final training loss: 0.23633846949324774\n",
      "\n",
      "Final validation R2: 0.5769448315831333\n",
      "Average validation test R2:  0.5769448315831333\n",
      "Final validation loss: 0.40018220697171414\n",
      "\n",
      "Final test R2: 0.5769448315831333\n",
      "Average final test R2:  0.5769448315831333\n",
      "Final test loss: 0.40018220697171414\n",
      "====================================================\n",
      "Target index: 4\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.04400 | Validation Loss: 0.02797\n",
      "Epoch: 02 | Train Loss: 0.02797 | Validation Loss: 0.02674\n",
      "Epoch: 03 | Train Loss: 0.02470 | Validation Loss: 0.02625\n",
      "Epoch: 04 | Train Loss: 0.02315 | Validation Loss: 0.02096\n",
      "Epoch: 05 | Train Loss: 0.02160 | Validation Loss: 0.02369\n",
      "Epoch: 06 | Train Loss: 0.02154 | Validation Loss: 0.02058\n",
      "Epoch: 07 | Train Loss: 0.01917 | Validation Loss: 0.02092\n",
      "Epoch: 08 | Train Loss: 0.01938 | Validation Loss: 0.02265\n",
      "Epoch: 09 | Train Loss: 0.01859 | Validation Loss: 0.01871\n",
      "Epoch: 10 | Train Loss: 0.01790 | Validation Loss: 0.01803\n",
      "====================================================\n",
      "Final training R2: 0.9837582549881316\n",
      "Average final training R2:  0.9837582549881316\n",
      "Final training loss: 0.014975359525463873\n",
      "\n",
      "Final validation R2: 0.9820904750572667\n",
      "Average validation test R2:  0.9820904750572667\n",
      "Final validation loss: 0.01730678037319404\n",
      "\n",
      "Final test R2: 0.9820904750572667\n",
      "Average final test R2:  0.9820904750572667\n",
      "Final test loss: 0.01730678037319404\n",
      "====================================================\n",
      "Target index: 5\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.17332 | Validation Loss: 0.14139\n",
      "Epoch: 02 | Train Loss: 0.10590 | Validation Loss: 0.10496\n",
      "Epoch: 03 | Train Loss: 0.08735 | Validation Loss: 0.10214\n",
      "Epoch: 04 | Train Loss: 0.07605 | Validation Loss: 0.08863\n",
      "Epoch: 05 | Train Loss: 0.06856 | Validation Loss: 0.08288\n",
      "Epoch: 06 | Train Loss: 0.06274 | Validation Loss: 0.08771\n",
      "Epoch: 07 | Train Loss: 0.05879 | Validation Loss: 0.07873\n",
      "Epoch: 08 | Train Loss: 0.05439 | Validation Loss: 0.07520\n",
      "Epoch: 09 | Train Loss: 0.05165 | Validation Loss: 0.07298\n",
      "Epoch: 10 | Train Loss: 0.04852 | Validation Loss: 0.07111\n",
      "====================================================\n",
      "Final training R2: 0.9239106174774947\n",
      "Average final training R2:  0.9239106174774947\n",
      "Final training loss: 0.07218264182511748\n",
      "\n",
      "Final validation R2: 0.8884265437619876\n",
      "Average validation test R2:  0.8884265437619876\n",
      "Final validation loss: 0.10475101423127434\n",
      "\n",
      "Final test R2: 0.8884265437619876\n",
      "Average final test R2:  0.8884265437619876\n",
      "Final test loss: 0.10475101423127434\n",
      "====================================================\n",
      "Target index: 6\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.07554 | Validation Loss: 0.04613\n",
      "Epoch: 02 | Train Loss: 0.04096 | Validation Loss: 0.03772\n",
      "Epoch: 03 | Train Loss: 0.03321 | Validation Loss: 0.03319\n",
      "Epoch: 04 | Train Loss: 0.02912 | Validation Loss: 0.02983\n",
      "Epoch: 05 | Train Loss: 0.02646 | Validation Loss: 0.03058\n",
      "Epoch: 06 | Train Loss: 0.02510 | Validation Loss: 0.02884\n",
      "Epoch: 07 | Train Loss: 0.02283 | Validation Loss: 0.03214\n",
      "Epoch: 08 | Train Loss: 0.02164 | Validation Loss: 0.02445\n",
      "Epoch: 09 | Train Loss: 0.02048 | Validation Loss: 0.02475\n",
      "Epoch: 10 | Train Loss: 0.02006 | Validation Loss: 0.02477\n",
      "====================================================\n",
      "Final training R2: 0.9764484978252937\n",
      "Average final training R2:  0.9764484978252937\n",
      "Final training loss: 0.022788920263732866\n",
      "\n",
      "Final validation R2: 0.9680273365942684\n",
      "Average validation test R2:  0.9680273365942684\n",
      "Final validation loss: 0.03108903232182806\n",
      "\n",
      "Final test R2: 0.9680273365942684\n",
      "Average final test R2:  0.9680273365942684\n",
      "Final test loss: 0.03108903232182806\n",
      "====================================================\n",
      "Target index: 7\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.10338 | Validation Loss: 0.06551\n",
      "Epoch: 02 | Train Loss: 0.05750 | Validation Loss: 0.05624\n",
      "Epoch: 03 | Train Loss: 0.04631 | Validation Loss: 0.04976\n",
      "Epoch: 04 | Train Loss: 0.04069 | Validation Loss: 0.04422\n",
      "Epoch: 05 | Train Loss: 0.03661 | Validation Loss: 0.04396\n",
      "Epoch: 06 | Train Loss: 0.03423 | Validation Loss: 0.04079\n",
      "Epoch: 07 | Train Loss: 0.03125 | Validation Loss: 0.04402\n",
      "Epoch: 08 | Train Loss: 0.02943 | Validation Loss: 0.03780\n",
      "Epoch: 09 | Train Loss: 0.02772 | Validation Loss: 0.03627\n",
      "Epoch: 10 | Train Loss: 0.02696 | Validation Loss: 0.03535\n",
      "====================================================\n",
      "Final training R2: 0.963342924818905\n",
      "Average final training R2:  0.963342924818905\n",
      "Final training loss: 0.0357593496387384\n",
      "\n",
      "Final validation R2: 0.949599540064953\n",
      "Average validation test R2:  0.949599540064953\n",
      "Final validation loss: 0.04867044879378787\n",
      "\n",
      "Final test R2: 0.949599540064953\n",
      "Average final test R2:  0.949599540064953\n",
      "Final test loss: 0.04867044879378787\n",
      "====================================================\n",
      "Target index: 8\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.06556 | Validation Loss: 0.04751\n",
      "Epoch: 02 | Train Loss: 0.04461 | Validation Loss: 0.05775\n",
      "Epoch: 03 | Train Loss: 0.03961 | Validation Loss: 0.03951\n",
      "Epoch: 04 | Train Loss: 0.03582 | Validation Loss: 0.04089\n",
      "Epoch: 05 | Train Loss: 0.03273 | Validation Loss: 0.03434\n",
      "Epoch: 06 | Train Loss: 0.03150 | Validation Loss: 0.03207\n",
      "Epoch: 07 | Train Loss: 0.02974 | Validation Loss: 0.03260\n",
      "Epoch: 08 | Train Loss: 0.02816 | Validation Loss: 0.03069\n",
      "Epoch: 09 | Train Loss: 0.02675 | Validation Loss: 0.02927\n",
      "Epoch: 10 | Train Loss: 0.02597 | Validation Loss: 0.02893\n",
      "====================================================\n",
      "Final training R2: 0.9630322054156725\n",
      "Average final training R2:  0.9630322054156725\n",
      "Final training loss: 0.036307293475723604\n",
      "\n",
      "Final validation R2: 0.9519484395858069\n",
      "Average validation test R2:  0.9519484395858069\n",
      "Final validation loss: 0.04785628829939434\n",
      "\n",
      "Final test R2: 0.9519484395858069\n",
      "Average final test R2:  0.9519484395858069\n",
      "Final test loss: 0.04785628829939434\n",
      "====================================================\n",
      "Target index: 9\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.02876 | Validation Loss: 0.01810\n",
      "Epoch: 02 | Train Loss: 0.01955 | Validation Loss: 0.01962\n",
      "Epoch: 03 | Train Loss: 0.01726 | Validation Loss: 0.01742\n",
      "Epoch: 04 | Train Loss: 0.01642 | Validation Loss: 0.01555\n",
      "Epoch: 05 | Train Loss: 0.01465 | Validation Loss: 0.01383\n",
      "Epoch: 06 | Train Loss: 0.01459 | Validation Loss: 0.01151\n",
      "Epoch: 07 | Train Loss: 0.01326 | Validation Loss: 0.01466\n",
      "Epoch: 08 | Train Loss: 0.01311 | Validation Loss: 0.01149\n",
      "Epoch: 09 | Train Loss: 0.01214 | Validation Loss: 0.01027\n",
      "Epoch: 10 | Train Loss: 0.01153 | Validation Loss: 0.00963\n",
      "====================================================\n",
      "Final training R2: 0.9973135638343359\n",
      "Average final training R2:  0.9973135638343359\n",
      "Final training loss: 0.002565757886594986\n",
      "\n",
      "Final validation R2: 0.9972106952544333\n",
      "Average validation test R2:  0.9972106952544333\n",
      "Final validation loss: 0.0027575755602111504\n",
      "\n",
      "Final test R2: 0.9972106952544333\n",
      "Average final test R2:  0.9972106952544333\n",
      "Final test loss: 0.0027575755602111504\n",
      "====================================================\n",
      "Target index: 10\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.03174 | Validation Loss: 0.01712\n",
      "Epoch: 02 | Train Loss: 0.01830 | Validation Loss: 0.01684\n",
      "Epoch: 03 | Train Loss: 0.01419 | Validation Loss: 0.01442\n",
      "Epoch: 04 | Train Loss: 0.01258 | Validation Loss: 0.01113\n",
      "Epoch: 05 | Train Loss: 0.01171 | Validation Loss: 0.01037\n",
      "Epoch: 06 | Train Loss: 0.01139 | Validation Loss: 0.00937\n",
      "Epoch: 07 | Train Loss: 0.00967 | Validation Loss: 0.01069\n",
      "Epoch: 08 | Train Loss: 0.00916 | Validation Loss: 0.00863\n",
      "Epoch: 09 | Train Loss: 0.00873 | Validation Loss: 0.00913\n",
      "Epoch: 10 | Train Loss: 0.00826 | Validation Loss: 0.00838\n",
      "====================================================\n",
      "Final training R2: 0.9966122513355292\n",
      "Average final training R2:  0.9966122513355292\n",
      "Final training loss: 0.0033917944132988297\n",
      "\n",
      "Final validation R2: 0.9966151274029895\n",
      "Average validation test R2:  0.9966151274029895\n",
      "Final validation loss: 0.0034220350339287855\n",
      "\n",
      "Final test R2: 0.9966151274029895\n",
      "Average final test R2:  0.9966151274029895\n",
      "Final test loss: 0.0034220350339287855\n",
      "====================================================\n",
      "Target index: 11\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.03172 | Validation Loss: 0.01718\n",
      "Epoch: 02 | Train Loss: 0.01833 | Validation Loss: 0.01662\n",
      "Epoch: 03 | Train Loss: 0.01422 | Validation Loss: 0.01473\n",
      "Epoch: 04 | Train Loss: 0.01260 | Validation Loss: 0.01119\n",
      "Epoch: 05 | Train Loss: 0.01169 | Validation Loss: 0.01040\n",
      "Epoch: 06 | Train Loss: 0.01140 | Validation Loss: 0.00942\n",
      "Epoch: 07 | Train Loss: 0.00965 | Validation Loss: 0.01078\n",
      "Epoch: 08 | Train Loss: 0.00912 | Validation Loss: 0.00853\n",
      "Epoch: 09 | Train Loss: 0.00865 | Validation Loss: 0.00903\n",
      "Epoch: 10 | Train Loss: 0.00813 | Validation Loss: 0.00830\n",
      "====================================================\n",
      "Final training R2: 0.9965782607102938\n",
      "Average final training R2:  0.9965782607102938\n",
      "Final training loss: 0.003426055808888515\n",
      "\n",
      "Final validation R2: 0.996580239315924\n",
      "Average validation test R2:  0.996580239315924\n",
      "Final validation loss: 0.0034558665595865864\n",
      "\n",
      "Final test R2: 0.996580239315924\n",
      "Average final test R2:  0.996580239315924\n",
      "Final test loss: 0.0034558665595865864\n",
      "====================================================\n",
      "Target index: 12\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.03171 | Validation Loss: 0.01715\n",
      "Epoch: 02 | Train Loss: 0.01827 | Validation Loss: 0.01646\n",
      "Epoch: 03 | Train Loss: 0.01417 | Validation Loss: 0.01454\n",
      "Epoch: 04 | Train Loss: 0.01259 | Validation Loss: 0.01110\n",
      "Epoch: 05 | Train Loss: 0.01173 | Validation Loss: 0.01039\n",
      "Epoch: 06 | Train Loss: 0.01147 | Validation Loss: 0.00955\n",
      "Epoch: 07 | Train Loss: 0.00978 | Validation Loss: 0.01095\n",
      "Epoch: 08 | Train Loss: 0.00925 | Validation Loss: 0.00867\n",
      "Epoch: 09 | Train Loss: 0.00884 | Validation Loss: 0.00933\n",
      "Epoch: 10 | Train Loss: 0.00833 | Validation Loss: 0.00851\n",
      "====================================================\n",
      "Final training R2: 0.9965023037093816\n",
      "Average final training R2:  0.9965023037093816\n",
      "Final training loss: 0.0035007855025782153\n",
      "\n",
      "Final validation R2: 0.9965043717004811\n",
      "Average validation test R2:  0.9965043717004811\n",
      "Final validation loss: 0.0035348657407806828\n",
      "\n",
      "Final test R2: 0.9965043717004811\n",
      "Average final test R2:  0.9965043717004811\n",
      "Final test loss: 0.0035348657407806828\n",
      "====================================================\n",
      "Target index: 13\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.03173 | Validation Loss: 0.01733\n",
      "Epoch: 02 | Train Loss: 0.01833 | Validation Loss: 0.01700\n",
      "Epoch: 03 | Train Loss: 0.01420 | Validation Loss: 0.01470\n",
      "Epoch: 04 | Train Loss: 0.01258 | Validation Loss: 0.01106\n",
      "Epoch: 05 | Train Loss: 0.01168 | Validation Loss: 0.01034\n",
      "Epoch: 06 | Train Loss: 0.01137 | Validation Loss: 0.00934\n",
      "Epoch: 07 | Train Loss: 0.00962 | Validation Loss: 0.01061\n",
      "Epoch: 08 | Train Loss: 0.00906 | Validation Loss: 0.00855\n",
      "Epoch: 09 | Train Loss: 0.00864 | Validation Loss: 0.00906\n",
      "Epoch: 10 | Train Loss: 0.00818 | Validation Loss: 0.00844\n",
      "====================================================\n",
      "Final training R2: 0.9964255109118114\n",
      "Average final training R2:  0.9964255109118114\n",
      "Final training loss: 0.003575427497559682\n",
      "\n",
      "Final validation R2: 0.996424771122768\n",
      "Average validation test R2:  0.996424771122768\n",
      "Final validation loss: 0.003609875014472681\n",
      "\n",
      "Final test R2: 0.996424771122768\n",
      "Average final test R2:  0.996424771122768\n",
      "Final test loss: 0.003609875014472681\n",
      "====================================================\n",
      "Target index: 14\n",
      "Device used: cuda\n",
      "Epoch: 01 | Train Loss: 0.03731 | Validation Loss: 0.02793\n",
      "Epoch: 02 | Train Loss: 0.02383 | Validation Loss: 0.03242\n",
      "Epoch: 03 | Train Loss: 0.02273 | Validation Loss: 0.02239\n",
      "Epoch: 04 | Train Loss: 0.02138 | Validation Loss: 0.01921\n",
      "Epoch: 05 | Train Loss: 0.01971 | Validation Loss: 0.02085\n",
      "Epoch: 06 | Train Loss: 0.02017 | Validation Loss: 0.01826\n",
      "Epoch: 07 | Train Loss: 0.01847 | Validation Loss: 0.01982\n",
      "Epoch: 08 | Train Loss: 0.01803 | Validation Loss: 0.01715\n",
      "Epoch: 09 | Train Loss: 0.01707 | Validation Loss: 0.01717\n",
      "Epoch: 10 | Train Loss: 0.01632 | Validation Loss: 0.01594\n",
      "====================================================\n",
      "Final training R2: 0.9928480030510326\n",
      "Average final training R2:  0.9928480030510326\n",
      "Final training loss: 0.006829814656773614\n",
      "\n",
      "Final validation R2: 0.9920635099112487\n",
      "Average validation test R2:  0.9920635099112487\n",
      "Final validation loss: 0.007648376525769261\n",
      "\n",
      "Final test R2: 0.9920635099112487\n",
      "Average final test R2:  0.9920635099112487\n",
      "Final test loss: 0.007648376525769261\n",
      "====================================================\n",
      "...Done...\n",
      "Time taken: 6.866024196147919 minutes\n",
      "Average time per target: 0.45773494640986123 minutes\n"
     ]
    }
   ],
   "source": [
    "feature_dim = train_data[:][0].shape[1]\n",
    "target_dim = 1\n",
    "\n",
    "def train(batch, target_idx):\n",
    "      features = batch[:][0]\n",
    "      targets = batch[:][1][:,target_idx].unsqueeze(-1)\n",
    "      \n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(features).to(device)  # Perform a single forward pass.\n",
    "\n",
    "      loss = criterion(out, targets) \n",
    "\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      \n",
    "      return loss\n",
    "\n",
    "def test(data, target_idx):\n",
    "      for i, batch in enumerate(data):\n",
    "            features = batch[:][0]\n",
    "            targets = batch[:][1][:,target_idx].cpu().unsqueeze(-1)\n",
    "            \n",
    "            model.eval()\n",
    "            out = model(features).cpu()\n",
    "            \n",
    "            # Caculate R2    \n",
    "            r2_score_var = np.array([r2_score(targets.detach().numpy(), out.detach().numpy())])        \n",
    "            all_r2 = np.hstack((all_r2, r2_score_var)) if i != 0 else r2_score_var\n",
    "                  \n",
    "            loss = float(criterion(out, targets).detach().numpy())\n",
    "            all_loss = np.hstack((all_loss, loss)) if i != 0 else np.array(loss)\n",
    "\n",
    "      average_test_r2 = np.mean(all_r2)\n",
    "      average_test_loss = np.mean(all_loss)\n",
    "      \n",
    "      return average_test_r2, average_test_loss\n",
    "\n",
    "num_targets = train_data[:][1].shape[1]\n",
    "start_time = time.time()\n",
    "for target_index in range(num_targets):\n",
    "      print(\"Target index:\", target_index)\n",
    "\n",
    "      model = GNN(hidden_channels=1024, feature_dim=feature_dim, target_dim=target_dim).to(device) \n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "      criterion = torch.nn.MSELoss().to(device)\n",
    "      \n",
    "      # Decay for learning rate\n",
    "      decayRate = 0.9\n",
    "      lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "      # Vectors to append accuracy to:\n",
    "      train_r2 = []\n",
    "      train_loss = []\n",
    "      test_r2 = []\n",
    "      test_loss = []\n",
    "      val_r2 = []\n",
    "      val_loss = []\n",
    "\n",
    "      n_epochs = 10\n",
    "\n",
    "      print(\"Device used:\", device)\n",
    "\n",
    "      for epoch in np.arange(1, n_epochs+1):\n",
    "            losses = []\n",
    "            for data in train_loader:\n",
    "                  loss = train(data, target_index)\n",
    "                  losses.append(loss.cpu().detach().numpy())  \n",
    "            # Compute validation loss\n",
    "            with torch.no_grad():\n",
    "                  val_losses = []\n",
    "                  for batch in val_loader:\n",
    "                        features = batch[:][0]\n",
    "                        targets = batch[:][1][:, target_index].unsqueeze(-1)\n",
    "                        out = model(features)\n",
    "                        val_losses.append(criterion(out, targets).cpu().detach().numpy())\n",
    "            print(f\"Epoch: {epoch:02d} | Train Loss: {np.mean(losses):.5f} | Validation Loss: {np.mean(val_losses):.5f}\")\n",
    "            \n",
    "            lr_scheduler.step() # Decay to learning rate\n",
    "                  \n",
    "            if epoch == n_epochs:         # calculate results of training: test on all data\n",
    "                  test_start = time.time()\n",
    "                  r2_temp_train, loss_temp_train = test(train_loader, target_index) \n",
    "                  train_r2.append(r2_temp_train)\n",
    "                  train_loss.append(loss_temp_train)\n",
    "                  \n",
    "                  r2_temp_val, loss_temp_val = test(test_loader, target_index)\n",
    "                  val_r2.append(r2_temp_val)\n",
    "                  val_loss.append(loss_temp_val)\n",
    "                  \n",
    "                  r2_temp_test, loss_temp_test = test(test_loader, target_index)\n",
    "                  test_r2.append(r2_temp_test)\n",
    "                  test_loss.append(loss_temp_test)\n",
    "\n",
    "                  print(\"====================================================\")\n",
    "                  print(\"Final training R2:\", train_r2[-1])\n",
    "                  print(\"Average final training R2: \", np.mean(train_r2[-1]))\n",
    "                  print(\"Final training loss:\", train_loss[-1])\n",
    "                  print()\n",
    "                  print(\"Final validation R2:\", val_r2[-1])\n",
    "                  print(\"Average validation test R2: \", np.mean(val_r2[-1]))\n",
    "                  print(\"Final validation loss:\", val_loss[-1])\n",
    "                  print()\n",
    "                  print(\"Final test R2:\", test_r2[-1])\n",
    "                  print(\"Average final test R2: \", np.mean(test_r2[-1]))\n",
    "                  print(\"Final test loss:\", test_loss[-1])\n",
    "                  print(\"====================================================\")\n",
    "                                    \n",
    "print(\"...Done...\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {(end_time - start_time)/60} minutes\")\n",
    "print(f\"Average time per target: {(end_time - start_time)/(num_targets*60)} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
