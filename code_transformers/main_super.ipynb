{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import atomInSmiles\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from code_graphs.utility_functions import get_num_parameters , get_data_split_indices, scale_targets\n",
    "from classes import create_encoded_vector, PositionalEncoding, TransformerLayer\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will attempt to gather all the variant in this file then changing if descriptors are used etc by only changing bools instead of having four different files.\n",
    "Alot of redundancy this way bit the program is much shorter, we do all calcualtion as if we are using both descriptors and fingerprints. But do not concat them in the transformerencoder if their bool is set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDescriptors = False\n",
    "useFingerprints = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "device: cuda\n",
      "cuda version: 11.7\n",
      "gpu: NVIDIA GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check if cuda is available\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda version:', torch.version.cuda)\n",
    "    print('gpu:', torch.cuda.get_device_name(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132820, 21)\n",
      "(132820, 179)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/smiles_and_targets.csv\")\n",
    "print(np.shape(df))\n",
    "\n",
    "mol_descriptor = np.load(\"../data/mol_descriptors.npy\")\n",
    "mol_fingerprint = np.load(\"../data/mol_morgan_fingerprints.npy\")\n",
    "print(mol_descriptor.shape)\n",
    "\n",
    "\n",
    "properties_names = ['A', 'B', 'C', 'mu', 'alfa', 'homo', 'lumo', 'gap', 'RÂ²', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "\n",
    "x_smiles = df.smiles.values\n",
    "y_targets = df.loc[:, properties_names].values # shape = (n_samples, n_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest word (max amount of tokens): 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenList = []\n",
    "for smile in x_smiles:\n",
    "    tokenList.append(atomInSmiles.encode(smile).split())\n",
    "#tokenList is target\n",
    "\n",
    "# find longest word (max tokens from one smile+1)\n",
    "maxTokenLength = 0\n",
    "for token in tokenList:\n",
    "    if len(token)>maxTokenLength:\n",
    "        maxTokenLength = len(token)\n",
    "print('Longest word (max amount of tokens):', maxTokenLength)\n",
    "\n",
    "# Give each token a index in a dictionary\n",
    "tokenDict = {}\n",
    "count = 1\n",
    "\n",
    "dictList = []\n",
    "for itokens in tokenList:\n",
    "    for itoke in itokens:\n",
    "        #print(itoke)\n",
    "        if tokenDict.get(itoke) == None:\n",
    "            tokenDict[itoke] = count\n",
    "        \n",
    "            # current = [itoke, count]\n",
    "            # dictList.append(current)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedTokens = []\n",
    "for token in tokenList:\n",
    "    encodedTokens.append(create_encoded_vector(token,tokenDict,maxTokenLength))\n",
    "    \n",
    "encodedTokens = np.array(encodedTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetwork(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,output_dim, vocab_size, embedding_dim, num_heads, maxTokenLength,\n",
    "                  nDescriptors,nFingerprints, useDescriptors, useFingerprints):\n",
    "        super().__init__()\n",
    "        # Embedd and add pos encoding to input\n",
    "        self.dropout_rate = 0.15\n",
    "        self.EmbeddingLayer = torch.nn.Embedding(num_embeddings=vocab_size,embedding_dim = embedding_dim , max_norm=True)\n",
    "        self.PositionalEncoding = PositionalEncoding(embedding_dim, maxTokenLength, dropout = self.dropout_rate)\n",
    "\n",
    "        self.TransEnc1 = TransformerLayer(embedding_dim,hidden_channels, num_heads, self.dropout_rate)\n",
    "        self.TransEnc2 = TransformerLayer(embedding_dim,hidden_channels, num_heads, self.dropout_rate)\n",
    "        self.TransEnc3 = TransformerLayer(embedding_dim,hidden_channels, num_heads, self.dropout_rate)\n",
    "        self.Pooling = torch.nn.AvgPool1d(kernel_size = maxTokenLength)\n",
    "\n",
    "        self.DenseOut1 = torch.nn.Linear(embedding_dim+nDescriptors+nFingerprints,hidden_channels)\n",
    "        self.DenseOut2 = torch.nn.Linear(hidden_channels,output_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.useDescriptors = useDescriptors\n",
    "        self.useFingerprints = useFingerprints\n",
    "\n",
    "\n",
    "    def forward(self,x,descriptors,fingerprints):\n",
    "        x = self.EmbeddingLayer(x)\n",
    "        x = self.PositionalEncoding(x)\n",
    "        x = self.TransEnc1(x)\n",
    "        x = self.TransEnc2(x)\n",
    "        x = self.TransEnc3(x)\n",
    "        # Permute so 22 dimension is compressed\n",
    "        x = self.Pooling(x.permute((0,2,1))).permute((0,2,1))\n",
    "        x = torch.squeeze(x,axis=1)\n",
    "        if self.useDescriptors and self.useFingerprints:\n",
    "            x = torch.cat((x,descriptors,fingerprints),1)\n",
    "        elif self.useDescriptors:\n",
    "            x = torch.cat((x,descriptors),1)\n",
    "        elif self.useFingerprints:\n",
    "            x = torch.cat((x,fingerprints),1)\n",
    "        \n",
    "        #x = x[:,-1,:]\n",
    "\n",
    "\n",
    "        x = self.DenseOut1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.DenseOut2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Divide into splits\n",
    "trainSplit, validationSplit, testSplit = get_data_split_indices(len(encodedTokens), 0.1, 0.1)\n",
    "\n",
    "# Training\n",
    "encodedTrainData = torch.tensor(encodedTokens[trainSplit], dtype=torch.long, device=device)\n",
    "trainTargets = y_targets[trainSplit]\n",
    "\n",
    "# Validation\n",
    "encodedValidationData = torch.tensor(encodedTokens[validationSplit], dtype=torch.long, device=device)\n",
    "validationTargets = y_targets[validationSplit]\n",
    "\n",
    "# Test\n",
    "encodedTestData = torch.tensor(encodedTokens[testSplit], dtype=torch.long, device=device)\n",
    "testTargets = y_targets[testSplit]\n",
    "\n",
    "trainTargets, validationTargets, testTargets, scalerTargets = scale_targets(trainTargets, validationTargets, testTargets)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Descriptors\n",
    "trainDescriptors = mol_descriptor[trainSplit]\n",
    "valDescriptors = mol_descriptor[validationSplit]\n",
    "testDescriptors = mol_descriptor[testSplit]\n",
    "# Normalize\n",
    "trainDescriptors = minmax_scaler.fit_transform(trainDescriptors)\n",
    "valDescriptors = minmax_scaler.transform(valDescriptors)\n",
    "testDescriptors = minmax_scaler.transform(testDescriptors)\n",
    "# Convert descriptors and fingerprints to tensors\n",
    "trainDescriptors = torch.from_numpy(trainDescriptors).float().to(device)\n",
    "valDescriptors = torch.from_numpy(valDescriptors).float().to(device)\n",
    "testDescriptors = torch.from_numpy(testDescriptors).float().to(device)\n",
    "\n",
    "# Fingerprints\n",
    "trainFingerprints = mol_fingerprint[trainSplit]\n",
    "valFingerprints = mol_fingerprint[validationSplit]\n",
    "testFingerprints = mol_fingerprint[testSplit]\n",
    "# Normalize\n",
    "trainFingerprints = minmax_scaler.fit_transform(trainFingerprints)\n",
    "valFingerprints = minmax_scaler.transform(valFingerprints)\n",
    "testFingerprints = minmax_scaler.transform(testFingerprints)\n",
    "# Convert to tensor\n",
    "trainFingerprints = torch.from_numpy(trainFingerprints).float().to(device)\n",
    "valFingerprints = torch.from_numpy(valFingerprints).float().to(device)\n",
    "testFingerprints = torch.from_numpy(testFingerprints).float().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert targets to tensors\n",
    "trainTargets = torch.tensor(trainTargets, dtype=torch.float, device=device)\n",
    "validationTargets = torch.tensor(validationTargets, dtype=torch.float, device=device)\n",
    "testTargets = torch.tensor(testTargets, dtype=torch.float, device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasetObject(Dataset):\n",
    "    def __init__(self,data,targets,descriptors,fingerprints):\n",
    "        self.data = data\n",
    "        self.descriptors = descriptors\n",
    "        self.targets = targets\n",
    "        self.fingerprints = fingerprints\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        target = self.targets[index]\n",
    "        descriptor = self.descriptors[index]\n",
    "        fingerprint = self.fingerprints[index]\n",
    "        return (sample), (target), (descriptor), (fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = DataLoader(datasetObject(encodedTrainData, trainTargets, trainDescriptors, trainFingerprints), batch_size)\n",
    "testData = DataLoader(datasetObject(encodedTestData, testTargets,  testDescriptors, testFingerprints), batch_size)\n",
    "validationData = DataLoader(datasetObject(encodedValidationData, validationTargets, valDescriptors, valFingerprints), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Epoch: 0 of 100 ####\n",
      " Training loss:\t0.38374125591464103\n",
      " Test loss:\t0.16081340496356672\n",
      " Validation loss:\t0.16362870656527007\n",
      "R2: [0.5108429406178903, 0.7232578060389188, 0.7996388604305918, 0.4546116750055115, 0.9327988847399895, 0.7281020942174762, 0.8687035822002025, 0.8490663172542275, 0.8630213242994386, 0.9550891897602777, 0.9709642882820945, 0.9701911344990284, 0.970418672447533, 0.9712976179074443, 0.9188793734451127]\n",
      "avg R2 0.8324589174097158 \n",
      "\n",
      "#### Epoch: 1 of 100 ####\n",
      " Training loss:\t0.15511158960975127\n",
      " Test loss:\t0.12839761147132286\n",
      " Validation loss:\t0.13139937474177435\n",
      "R2: [0.5979730990167523, 0.7754209110739141, 0.8402084163492453, 0.49783915599716144, 0.9549707434963735, 0.7678700764051689, 0.9056362661373405, 0.8812539974086557, 0.8845883504234192, 0.9701041512573775, 0.9897342169109984, 0.9899779427866644, 0.9900710924373001, 0.9897180678547065, 0.9517340120207447]\n",
      "avg R2 0.8658066999717217 \n",
      "\n",
      "#### Epoch: 2 of 100 ####\n",
      " Training loss:\t0.128608414238293\n",
      " Test loss:\t0.1102456129514254\n",
      " Validation loss:\t0.11272190167353703\n",
      "R2: [0.6463568787686002, 0.8047787280945685, 0.8678314636185946, 0.5239084481647331, 0.9710119983426506, 0.7905154119636282, 0.9216378604300295, 0.8943529620637979, 0.9095447194734269, 0.9905957558396516, 0.9944301837706191, 0.9943838610617409, 0.9941179059126839, 0.994267413649408, 0.9712171750027466]\n",
      "avg R2 0.884596717743792 \n",
      "\n",
      "#### Epoch: 3 of 100 ####\n",
      " Training loss:\t0.11574360148724414\n",
      " Test loss:\t0.10345995426177979\n",
      " Validation loss:\t0.10587406158447266\n",
      "R2: [0.678458779408429, 0.8145016443385409, 0.8749148977649774, 0.5365845440916075, 0.9736324493121699, 0.8075094960984615, 0.9273767446897837, 0.9006516434148265, 0.913716036905834, 0.9887463268649832, 0.9953339425086578, 0.995405685223398, 0.9953349830613598, 0.9953695375282966, 0.9746115471170059]\n",
      "avg R2 0.8914765505552221 \n",
      "\n",
      "#### Epoch: 4 of 100 ####\n",
      " Training loss:\t0.10637782841544062\n",
      " Test loss:\t0.10113901358384353\n",
      " Validation loss:\t0.10357879675351657\n",
      "R2: [0.6895049372149218, 0.8234017306954536, 0.8797330147238872, 0.5509155967083244, 0.9648493404022713, 0.8113088905114656, 0.9316576154116559, 0.9071915693799715, 0.9154500067166901, 0.9917908702295841, 0.9929196822168461, 0.9928800476116021, 0.9930863170155159, 0.9931215192745196, 0.9705191835131176]\n",
      "avg R2 0.8938886881083883 \n",
      "\n",
      "#### Epoch: 5 of 100 ####\n",
      " Training loss:\t0.09915666390728477\n",
      " Test loss:\t0.09523671406965989\n",
      " Validation loss:\t0.09708264240851769\n",
      "R2: [0.7120639878493725, 0.8315922656196085, 0.8848422916532592, 0.5615845138363629, 0.9716075242504219, 0.820959297724824, 0.9367448876257534, 0.9117778350424873, 0.9232865042240124, 0.9945807346722491, 0.9935396382227804, 0.9934323109502871, 0.9934508682497236, 0.9936761138734033, 0.9764773983979592]\n",
      "avg R2 0.8999744114795003 \n",
      "\n",
      "#### Epoch: 6 of 100 ####\n",
      " Training loss:\t0.09365429496420642\n",
      " Test loss:\t0.09143892618326041\n",
      " Validation loss:\t0.0932225172336285\n",
      "R2: [0.7374174639688904, 0.8468307442783691, 0.8926509429882702, 0.575811530605992, 0.9741914082581106, 0.8291913662528797, 0.9386550269223121, 0.9162573986517647, 0.9298462251219253, 0.9952611402526274, 0.9853929708954238, 0.9857257772646325, 0.9857025497125973, 0.98580312773329, 0.9780792388581795]\n",
      "avg R2 0.9037877941176842 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m earlyStop \u001b[39mand\u001b[39;00m epoch \u001b[39m<\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[0;32m     60\u001b[0m       loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 61\u001b[0m       \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m,targets,descriptor,fingerprint \u001b[39min\u001b[39;00m trainingData:\n\u001b[0;32m     62\u001b[0m             loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train(\u001b[39minput\u001b[39m,targets,descriptor,fingerprint)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     64\u001b[0m       test \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\j031m\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:629\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 629\u001b[0m     \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_profile_name):\n\u001b[0;32m    630\u001b[0m         \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[0;32m    631\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[0;32m    632\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\j031m\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\profiler.py:495\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39m_record_function_enter_new(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m--> 495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[0;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit:\n\u001b[0;32m    497\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_channels = 512\n",
    "embedding_dim = 128\n",
    "d_target = 15\n",
    "nHeads = 4\n",
    "learningRate = 0.0005\n",
    "if useDescriptors:\n",
    "      nDescriptors = len(mol_descriptor[0])\n",
    "else:\n",
    "      nDescriptors = 0\n",
    "\n",
    "if useFingerprints:\n",
    "      nFingerprints = len(mol_fingerprint[0])\n",
    "else:\n",
    "      nFingerprints = 0\n",
    "\n",
    "vocab_size = len(tokenDict)+1\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "model = TransformerNetwork(hidden_channels,d_target,vocab_size, embedding_dim, nHeads,maxTokenLength,\n",
    "                           nDescriptors,nFingerprints,useDescriptors,useFingerprints).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=0)\n",
    "# decay learning rate\n",
    "decayRate = 1\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "def train(data_in, targets, descriptors, fingerprints):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data_in,descriptors,fingerprints).to(device)\n",
    "      loss = criterion(out, targets)\n",
    "      \n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "# This calculates r2 for each target separately \n",
    "def inferNew(data_in, targets, descriptors, fingerprints):\n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = model(data_in, descriptors, fingerprints).to(device)\n",
    "            loss = criterion(out, targets)\n",
    "\n",
    "            r2_scores = []\n",
    "            for item in range(targets.shape[1]):\n",
    "                  r2 = r2_score(targets[:, item].cpu().detach().numpy(), out[:, item].cpu().detach().numpy())\n",
    "                  r2_scores.append(r2)\n",
    "\n",
    "    return loss, r2_scores\n",
    "\n",
    "\n",
    "earlyStop = False\n",
    "stopTolerance = 3\n",
    "minDiff = 0.01\n",
    "counter = 0\n",
    "epoch = 0\n",
    "lossList = []\n",
    "r2List = []\n",
    "while not earlyStop and epoch < 100:\n",
    "      loss = 0\n",
    "      for input,targets,descriptor,fingerprint in trainingData:\n",
    "            loss += train(input,targets,descriptor,fingerprint).detach()\n",
    "      \n",
    "      test = 0\n",
    "      r2 = [0]*d_target\n",
    "      for input, targets, descriptor, fingerprint in testData:\n",
    "            tempTest, tempR2 = inferNew(input,targets,descriptor,fingerprint)\n",
    "            test += tempTest\n",
    "            # Add r2 for each variable\n",
    "            r2 = [x + y for x, y in zip(r2, tempR2)]\n",
    "      # Average over batch\n",
    "      r2 = [x / len(testData) for x in r2]\n",
    "      r2List.append(r2)\n",
    "\n",
    "      val = 0\n",
    "      for input,targets,descriptor,fingerprint in validationData:\n",
    "            tempVal,tempR2 = inferNew(input,targets, descriptor, fingerprint)\n",
    "            val += tempVal\n",
    "      \n",
    "      lr_scheduler.step()\n",
    "\n",
    "      # Save loss AS PYTHON NUMBER (not tensor) in list\n",
    "      lossList.append([loss.item()/len(trainingData), test.item()/len(testData), val.item()/len(validationData)])\n",
    "\n",
    "      # Early stopping\n",
    "      if (lossList[epoch][2]-lossList[epoch][0]) > minDiff:\n",
    "            counter += 1\n",
    "      else:\n",
    "            counter = 0\n",
    "            if counter >= stopTolerance:\n",
    "                  earlyStop = True\n",
    "\n",
    "      print(f\"#### Epoch: {epoch} of 100 ####\\n Training loss:\\t{lossList[epoch][0]}\\n Test loss:\\t{lossList[epoch][1]}\\n Validation loss:\\t{lossList[epoch][2]}\")\n",
    "      print('R2:', r2List[epoch])\n",
    "      print('avg R2',np.mean(r2List[epoch]),'\\n')\n",
    "      epoch+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7374174639688904, 0.8468307442783691, 0.8926509429882702, 0.575811530605992, 0.9741914082581106, 0.8291913662528797, 0.9386550269223121, 0.9162573986517647, 0.9298462251219253, 0.9952611402526274, 0.9853929708954238, 0.9857257772646325, 0.9857025497125973, 0.98580312773329, 0.9780792388581795]\n",
      "0.9037877941176842\n",
      "[0.7374174639688904, 0.8468307442783691, 0.8926509429882702, 0.9741914082581106, 0.8291913662528797, 0.9386550269223121, 0.9162573986517647, 0.9298462251219253, 0.9952611402526274, 0.9853929708954238, 0.9857257772646325, 0.9857025497125973, 0.98580312773329, 0.9780792388581795]\n",
      "0.9272146700828049\n"
     ]
    }
   ],
   "source": [
    "lastRow = r2List[-1]\n",
    "print(lastRow)\n",
    "print(np.mean(lastRow))\n",
    "\n",
    "del(lastRow[3])\n",
    "print(lastRow)\n",
    "print(np.mean(lastRow))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
