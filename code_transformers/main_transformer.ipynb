{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIF360 Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main source: https://www.kaggle.com/code/rmonge/predicting-molecule-properties-based-on-its-smiles/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATED ON 15/05-2023  11:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import atomInSmiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is list of strings on the form ['a','b','c']\n",
    "# where the string are tokens\n",
    "# Dictionary is the dictionary containign all possible tokens\n",
    "# and an index for them\n",
    "# MaxTokenLength is the max amount of tokens any input creates\n",
    "def create_Onehot_Matrix(input, dictionary,maxTokenLength):\n",
    "    # Create a matrix of zeros\n",
    "    onehot_Matrix = np.zeros((len(dictionary),maxTokenLength))\n",
    "    \n",
    "    # Change value in right place to one\n",
    "    keyCount = 0\n",
    "    for key in input:\n",
    "        onehot_Matrix[dictionary[key],keyCount] = 1\n",
    "        keyCount+=1\n",
    "\n",
    "    # Return it\n",
    "    return(onehot_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input is list of strings on the form ['a','b','c']\n",
    "# where the string are tokens\n",
    "# Dictionary is the dictionary containign all possible tokens\n",
    "# and an index for them\n",
    "# MaxTokenLength is the max amount of tokens any input creates\n",
    "\n",
    "# THIS VERSION RETURNS TORCH TENSOR\n",
    "\n",
    "#Version taht returns tensor\n",
    "def create_encoded_tensor(input, dictionary,maxTokenLength):\n",
    "    # Create a matrix of zeros\n",
    "    #encoded_vector = np.zeros((1,maxTokenLength))\n",
    "    encoded_tensor = torch.zeros(maxTokenLength,dtype=torch.long)\n",
    "    \n",
    "    # Change value in right place to one\n",
    "    keyCount = 0\n",
    "    for key in input:\n",
    "        encoded_tensor[keyCount] = dictionary[key]\n",
    "        keyCount+=1\n",
    "    \n",
    "    return encoded_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132820, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/smiles_and_targets.csv\")\n",
    "print(np.shape(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "properties_names = ['A', 'B', 'C', 'mu', 'alfa', 'homo', 'lumo', 'gap', 'RÂ²', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "\n",
    "x_smiles = df.smiles.values\n",
    "y = torch.tensor(df.loc[:, properties_names].values, dtype=torch.float32)  # shape = (n_samples, n_properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC(C)C#N\n",
      "['[CH3;!R;C]', '[CH;!R;CCC]', '(', '[CH3;!R;C]', ')', '[C;!R;CN]', '#', '[N;!R;C]']\n",
      "(132820,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testSmile = x_smiles[8]\n",
    "print(testSmile)\n",
    "tokens = atomInSmiles.encode(testSmile)\n",
    "tokens = tokens.split()\n",
    "print(tokens)\n",
    "print(x_smiles.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest word (max amount of tokens): 22\n"
     ]
    }
   ],
   "source": [
    "# tokenize all smiles\n",
    "#import atomInSmiles\n",
    "\n",
    "tokenList = []\n",
    "for smile in x_smiles:\n",
    "    tokenList.append(atomInSmiles.encode(smile).split())\n",
    "#tokenList is target\n",
    "\n",
    "# find longest word (max tokens from one smile+1)\n",
    "maxTokenLength = 0\n",
    "for token in tokenList:\n",
    "    if len(token)>maxTokenLength:\n",
    "        maxTokenLength = len(token)\n",
    "print('Longest word (max amount of tokens):', maxTokenLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Give each token a index in a dictionary\n",
    "tokenDict = {}\n",
    "count = 1\n",
    "\n",
    "dictList = []\n",
    "for itokens in tokenList:\n",
    "    for itoke in itokens:\n",
    "        #print(itoke)\n",
    "        if tokenDict.get(itoke) == None:\n",
    "            tokenDict[itoke] = count\n",
    "        \n",
    "            # current = [itoke, count]\n",
    "            # dictList.append(current)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([132820, 22])\n"
     ]
    }
   ],
   "source": [
    "encodedTensors = torch.tensor([],dtype=int)\n",
    "for token in tokenList:\n",
    "    encodedTensors = torch.cat((encodedTensors,create_encoded_tensor(token,tokenDict,maxTokenLength)),dim=0)\n",
    "\n",
    "print(encodedTensors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From attention is all you need\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, max_len,dropout):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x + torch.tensor(self.pe[:, :x.size(1)], \n",
    "        #                  requires_grad=False)\n",
    "        x = x + self.pe[:x.size(0), :].detach()\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6, 22,  8, 15,  9, 26, 18, 10, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0],\n",
      "        [17, 10, 78, 33, 34, 35,  8, 15,  9, 34, 33,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "torch.Size([2, 22, 64])\n",
      "tensor([[[-0.1868,  1.1513,  0.4625,  ..., -0.7419,  1.0518, -1.1054],\n",
      "         [-1.8999,  1.1342, -0.4428,  ...,  0.0293, -0.2000, -0.0839],\n",
      "         [ 0.8472, -0.4422,  0.9121,  ...,  2.9850,  1.7387, -1.0390],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.3443, -0.3187,  0.1928,  ..., -1.1231, -1.4207,  0.1440],\n",
      "         [ 0.9567,  0.9758, -1.7416,  ..., -0.8060, -0.8557, -1.2738],\n",
      "         [ 0.0918, -1.8911, -0.3763,  ...,  0.2317,  1.3684,  1.3230],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 22, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the size of the embedding space\n",
    "embedding_dim = 64\n",
    "vocab_size = len(tokenDict)\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "# Try two inputs and concat them (this will be done for batches)\n",
    "input_sentence = create_encoded_tensor(tokenList[100],tokenDict,maxTokenLength)\n",
    "other_input = create_encoded_tensor(tokenList[150],tokenDict,maxTokenLength)\n",
    "\n",
    "input_sentence = torch.cat((input_sentence,other_input),dim=0)\n",
    "print(input_sentence)\n",
    "\n",
    "# Pass the input tensor through the embedding layer\n",
    "embedded_tensor = embedding_layer(input_sentence)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(embedded_tensor.shape)  # should be (1, 22, 64)\n",
    "print(embedded_tensor)\n",
    "\n",
    "posencoder = PositionalEncoding(embedding_dim,maxTokenLength,0.1)\n",
    "encoded = posencoder.forward(embedded_tensor)\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerLayer(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.Attention = torch.nn.MultiheadAttention(embedding_dim,num_heads=4,dropout=0.15)\n",
    "        self.Norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.Dense1 = torch.nn.Linear(embedding_dim,hidden_channels)\n",
    "        self.Dense2 = torch.nn.Linear(hidden_channels,hidden_channels)\n",
    "        self.Norm2 = torch.nn.LayerNorm(hidden_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        addNormX = x\n",
    "        #print(x.shape)\n",
    "        x, _ = self.Attention(x,x,x)\n",
    "        #print('attention output',x.shape)\n",
    "        x = self.Norm1(x + addNormX)\n",
    "        #print('norm + input',x.shape)\n",
    "        addNormX = x\n",
    "        x = self.Dense1(x)\n",
    "        #print('first dense output',x.shape)\n",
    "        x = self.Dense2(x)\n",
    "        #print('second dense output',x.shape)\n",
    "        x = self.Norm2(x + addNormX)\n",
    "        #print(x.shape)\n",
    "\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetwork(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,output_dim, vocab_size, maxTokenLength):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.embedding_dim = 64\n",
    "        # Embedd and add pos encoding to input\n",
    "        self.EmbeddingLayer = torch.nn.Embedding(num_embeddings=vocab_size,embedding_dim = self.embedding_dim , max_norm=True)\n",
    "        self.PositionalEncoding = PositionalEncoding(self.embedding_dim, maxTokenLength, dropout = 0.1)\n",
    "\n",
    "        \n",
    "        self.TransEnc1 = TransformerLayer(self.embedding_dim,hidden_channels)\n",
    "        self.Pooling = torch.nn.AvgPool1d(kernel_size= 2)\n",
    "\n",
    "        self.DenseOut1 = torch.nn.Linear(embedding_dim,hidden_channels)\n",
    "        self.DenseOut2 = torch.nn.Linear(hidden_channels,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.EmbeddingLayer(x)\n",
    "        x = self.PositionalEncoding(x)\n",
    "        x = self.TransEnc1(x)\n",
    "        #x = self.Pooling(x)\n",
    "        x = x[:,-1,:]\n",
    "        x = self.DenseOut1(x)\n",
    "        x = self.DenseOut2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6938,  0.1116,  0.7285, -0.3562,  0.4006, -0.0077, -0.0471,  0.0307,\n",
      "          0.2455, -0.1964, -0.0895, -0.2404,  0.6831, -0.6525, -0.3149],\n",
      "        [-0.5684,  0.0187,  0.4665, -0.3207,  0.3235,  0.1496,  0.0632,  0.0263,\n",
      "          0.0735, -0.2491,  0.2192, -0.1793,  0.4808, -0.6225, -0.1946]],\n",
      "       grad_fn=<AddmmBackward0>) torch.Size([2, 15])\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerNetwork(64,15,len(tokenDict),maxTokenLength)\n",
    "input_sentence\n",
    "output = transformer.forward(input_sentence)\n",
    "print(output, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39873.1523, grad_fn=<MseLossBackward0>)\n",
      "tensor(39849.6328, grad_fn=<MseLossBackward0>)\n",
      "tensor(39826.4922, grad_fn=<MseLossBackward0>)\n",
      "tensor(39806.3164, grad_fn=<MseLossBackward0>)\n",
      "tensor(39781.9805, grad_fn=<MseLossBackward0>)\n",
      "tensor(39762.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(39741.3516, grad_fn=<MseLossBackward0>)\n",
      "tensor(39720.7656, grad_fn=<MseLossBackward0>)\n",
      "tensor(39701.8711, grad_fn=<MseLossBackward0>)\n",
      "tensor(39682.2383, grad_fn=<MseLossBackward0>)\n",
      "tensor(39665.6055, grad_fn=<MseLossBackward0>)\n",
      "tensor(39646.3672, grad_fn=<MseLossBackward0>)\n",
      "tensor(39627.7773, grad_fn=<MseLossBackward0>)\n",
      "tensor(39609.4297, grad_fn=<MseLossBackward0>)\n",
      "tensor(39589.8242, grad_fn=<MseLossBackward0>)\n",
      "tensor(39574.2422, grad_fn=<MseLossBackward0>)\n",
      "tensor(39554.4648, grad_fn=<MseLossBackward0>)\n",
      "tensor(39537.1211, grad_fn=<MseLossBackward0>)\n",
      "tensor(39518.2461, grad_fn=<MseLossBackward0>)\n",
      "tensor(39498.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(39479.9688, grad_fn=<MseLossBackward0>)\n",
      "tensor(39459.5742, grad_fn=<MseLossBackward0>)\n",
      "tensor(39438.7422, grad_fn=<MseLossBackward0>)\n",
      "tensor(39418.3086, grad_fn=<MseLossBackward0>)\n",
      "tensor(39396.6445, grad_fn=<MseLossBackward0>)\n",
      "tensor(39375.5234, grad_fn=<MseLossBackward0>)\n",
      "tensor(39352.2773, grad_fn=<MseLossBackward0>)\n",
      "tensor(39328.7891, grad_fn=<MseLossBackward0>)\n",
      "tensor(39305.1992, grad_fn=<MseLossBackward0>)\n",
      "tensor(39280.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(39254.5586, grad_fn=<MseLossBackward0>)\n",
      "tensor(39228.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(39202.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(39172.7656, grad_fn=<MseLossBackward0>)\n",
      "tensor(39145.0859, grad_fn=<MseLossBackward0>)\n",
      "tensor(39114.5859, grad_fn=<MseLossBackward0>)\n",
      "tensor(39083.3281, grad_fn=<MseLossBackward0>)\n",
      "tensor(39052.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(39020.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(38985.4023, grad_fn=<MseLossBackward0>)\n",
      "tensor(38952.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(38916.0547, grad_fn=<MseLossBackward0>)\n",
      "tensor(38879.1055, grad_fn=<MseLossBackward0>)\n",
      "tensor(38840.9727, grad_fn=<MseLossBackward0>)\n",
      "tensor(38802.7852, grad_fn=<MseLossBackward0>)\n",
      "tensor(38762.2109, grad_fn=<MseLossBackward0>)\n",
      "tensor(38720.9414, grad_fn=<MseLossBackward0>)\n",
      "tensor(38678.5273, grad_fn=<MseLossBackward0>)\n",
      "tensor(38636.4141, grad_fn=<MseLossBackward0>)\n",
      "tensor(38591.9492, grad_fn=<MseLossBackward0>)\n",
      "tensor(38545.3047, grad_fn=<MseLossBackward0>)\n",
      "tensor(38498.4297, grad_fn=<MseLossBackward0>)\n",
      "tensor(38450.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(38401.0898, grad_fn=<MseLossBackward0>)\n",
      "tensor(38349.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(38298.1211, grad_fn=<MseLossBackward0>)\n",
      "tensor(38245.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(38190.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(38135.4766, grad_fn=<MseLossBackward0>)\n",
      "tensor(38078.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(38020.2578, grad_fn=<MseLossBackward0>)\n",
      "tensor(37959.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(37900.0430, grad_fn=<MseLossBackward0>)\n",
      "tensor(37837.6211, grad_fn=<MseLossBackward0>)\n",
      "tensor(37773.3828, grad_fn=<MseLossBackward0>)\n",
      "tensor(37707.9453, grad_fn=<MseLossBackward0>)\n",
      "tensor(37641.8164, grad_fn=<MseLossBackward0>)\n",
      "tensor(37573.7109, grad_fn=<MseLossBackward0>)\n",
      "tensor(37505.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(37434.6602, grad_fn=<MseLossBackward0>)\n",
      "tensor(37362.3945, grad_fn=<MseLossBackward0>)\n",
      "tensor(37288.9688, grad_fn=<MseLossBackward0>)\n",
      "tensor(37213.8203, grad_fn=<MseLossBackward0>)\n",
      "tensor(37138.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(37060.2891, grad_fn=<MseLossBackward0>)\n",
      "tensor(36981.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(36901.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(36819.5430, grad_fn=<MseLossBackward0>)\n",
      "tensor(36735.6016, grad_fn=<MseLossBackward0>)\n",
      "tensor(36651.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(36564.9297, grad_fn=<MseLossBackward0>)\n",
      "tensor(36476.6133, grad_fn=<MseLossBackward0>)\n",
      "tensor(36388.2852, grad_fn=<MseLossBackward0>)\n",
      "tensor(36297.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(36205.2539, grad_fn=<MseLossBackward0>)\n",
      "tensor(36111.8555, grad_fn=<MseLossBackward0>)\n",
      "tensor(36017.7422, grad_fn=<MseLossBackward0>)\n",
      "tensor(35920.5703, grad_fn=<MseLossBackward0>)\n",
      "tensor(35823.0234, grad_fn=<MseLossBackward0>)\n",
      "tensor(35722.9961, grad_fn=<MseLossBackward0>)\n",
      "tensor(35622.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(35520.1211, grad_fn=<MseLossBackward0>)\n",
      "tensor(35416.3398, grad_fn=<MseLossBackward0>)\n",
      "tensor(35311.5977, grad_fn=<MseLossBackward0>)\n",
      "tensor(35204.5469, grad_fn=<MseLossBackward0>)\n",
      "tensor(35096.9023, grad_fn=<MseLossBackward0>)\n",
      "tensor(34987.1875, grad_fn=<MseLossBackward0>)\n",
      "tensor(34876.1016, grad_fn=<MseLossBackward0>)\n",
      "tensor(34763.3555, grad_fn=<MseLossBackward0>)\n",
      "tensor(34649.9492, grad_fn=<MseLossBackward0>)\n",
      "tensor(34534.5273, grad_fn=<MseLossBackward0>)\n",
      "tensor(34417.6328, grad_fn=<MseLossBackward0>)\n",
      "tensor(34299.4258, grad_fn=<MseLossBackward0>)\n",
      "tensor(34180.0742, grad_fn=<MseLossBackward0>)\n",
      "tensor(34059.1289, grad_fn=<MseLossBackward0>)\n",
      "tensor(33936.6328, grad_fn=<MseLossBackward0>)\n",
      "tensor(33812.8672, grad_fn=<MseLossBackward0>)\n",
      "tensor(33687.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(33561.1797, grad_fn=<MseLossBackward0>)\n",
      "tensor(33433.2422, grad_fn=<MseLossBackward0>)\n",
      "tensor(33303.3047, grad_fn=<MseLossBackward0>)\n",
      "tensor(33173.0625, grad_fn=<MseLossBackward0>)\n",
      "tensor(33041.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(32907.9961, grad_fn=<MseLossBackward0>)\n",
      "tensor(32772.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(32637.2578, grad_fn=<MseLossBackward0>)\n",
      "tensor(32499.4609, grad_fn=<MseLossBackward0>)\n",
      "tensor(32361.1309, grad_fn=<MseLossBackward0>)\n",
      "tensor(32221.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(32079.5547, grad_fn=<MseLossBackward0>)\n",
      "tensor(31937.2930, grad_fn=<MseLossBackward0>)\n",
      "tensor(31793.8516, grad_fn=<MseLossBackward0>)\n",
      "tensor(31649.0898, grad_fn=<MseLossBackward0>)\n",
      "tensor(31503.0098, grad_fn=<MseLossBackward0>)\n",
      "tensor(31355.4316, grad_fn=<MseLossBackward0>)\n",
      "tensor(31206.9941, grad_fn=<MseLossBackward0>)\n",
      "tensor(31056.9336, grad_fn=<MseLossBackward0>)\n",
      "tensor(30906.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(30754.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(30600.6777, grad_fn=<MseLossBackward0>)\n",
      "tensor(30446.6641, grad_fn=<MseLossBackward0>)\n",
      "tensor(30291.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(30134.4902, grad_fn=<MseLossBackward0>)\n",
      "tensor(29976.6035, grad_fn=<MseLossBackward0>)\n",
      "tensor(29817.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(29658.2402, grad_fn=<MseLossBackward0>)\n",
      "tensor(29497.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(29335.2676, grad_fn=<MseLossBackward0>)\n",
      "tensor(29172.1230, grad_fn=<MseLossBackward0>)\n",
      "tensor(29007.8555, grad_fn=<MseLossBackward0>)\n",
      "tensor(28843.3770, grad_fn=<MseLossBackward0>)\n",
      "tensor(28677.3965, grad_fn=<MseLossBackward0>)\n",
      "tensor(28510.8672, grad_fn=<MseLossBackward0>)\n",
      "tensor(28342.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(28174.1016, grad_fn=<MseLossBackward0>)\n",
      "tensor(28004.4180, grad_fn=<MseLossBackward0>)\n",
      "tensor(27833.8887, grad_fn=<MseLossBackward0>)\n",
      "tensor(27662.7246, grad_fn=<MseLossBackward0>)\n",
      "tensor(27490.3223, grad_fn=<MseLossBackward0>)\n",
      "tensor(27317.8926, grad_fn=<MseLossBackward0>)\n",
      "tensor(27143.5488, grad_fn=<MseLossBackward0>)\n",
      "tensor(26969.3594, grad_fn=<MseLossBackward0>)\n",
      "tensor(26794.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(26617.7363, grad_fn=<MseLossBackward0>)\n",
      "tensor(26441.2168, grad_fn=<MseLossBackward0>)\n",
      "tensor(26263.5840, grad_fn=<MseLossBackward0>)\n",
      "tensor(26085.6328, grad_fn=<MseLossBackward0>)\n",
      "tensor(25906.8086, grad_fn=<MseLossBackward0>)\n",
      "tensor(25727.4355, grad_fn=<MseLossBackward0>)\n",
      "tensor(25547.2754, grad_fn=<MseLossBackward0>)\n",
      "tensor(25366.7520, grad_fn=<MseLossBackward0>)\n",
      "tensor(25185.6914, grad_fn=<MseLossBackward0>)\n",
      "tensor(25003.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(24821.7383, grad_fn=<MseLossBackward0>)\n",
      "tensor(24638.9766, grad_fn=<MseLossBackward0>)\n",
      "tensor(24455.7031, grad_fn=<MseLossBackward0>)\n",
      "tensor(24272.0137, grad_fn=<MseLossBackward0>)\n",
      "tensor(24088.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(23903.1230, grad_fn=<MseLossBackward0>)\n",
      "tensor(23718.2930, grad_fn=<MseLossBackward0>)\n",
      "tensor(23533.1328, grad_fn=<MseLossBackward0>)\n",
      "tensor(23347.2285, grad_fn=<MseLossBackward0>)\n",
      "tensor(23161.5156, grad_fn=<MseLossBackward0>)\n",
      "tensor(22974.9902, grad_fn=<MseLossBackward0>)\n",
      "tensor(22788.4434, grad_fn=<MseLossBackward0>)\n",
      "tensor(22601.6406, grad_fn=<MseLossBackward0>)\n",
      "tensor(22414.9492, grad_fn=<MseLossBackward0>)\n",
      "tensor(22227.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(22040.0215, grad_fn=<MseLossBackward0>)\n",
      "tensor(21852.3262, grad_fn=<MseLossBackward0>)\n",
      "tensor(21664.3848, grad_fn=<MseLossBackward0>)\n",
      "tensor(21476.5312, grad_fn=<MseLossBackward0>)\n",
      "tensor(21288.5801, grad_fn=<MseLossBackward0>)\n",
      "tensor(21100.5820, grad_fn=<MseLossBackward0>)\n",
      "tensor(20912.8574, grad_fn=<MseLossBackward0>)\n",
      "tensor(20724.8633, grad_fn=<MseLossBackward0>)\n",
      "tensor(20536.8223, grad_fn=<MseLossBackward0>)\n",
      "tensor(20348.8398, grad_fn=<MseLossBackward0>)\n",
      "tensor(20161.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(19973.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(19785.5234, grad_fn=<MseLossBackward0>)\n",
      "tensor(19597.7949, grad_fn=<MseLossBackward0>)\n",
      "tensor(19410.6992, grad_fn=<MseLossBackward0>)\n",
      "tensor(19223.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(19036.7871, grad_fn=<MseLossBackward0>)\n",
      "tensor(18850.1230, grad_fn=<MseLossBackward0>)\n",
      "tensor(18663.9180, grad_fn=<MseLossBackward0>)\n",
      "tensor(18477.7832, grad_fn=<MseLossBackward0>)\n",
      "tensor(18292.4551, grad_fn=<MseLossBackward0>)\n",
      "tensor(18107.0723, grad_fn=<MseLossBackward0>)\n",
      "tensor(17922.1758, grad_fn=<MseLossBackward0>)\n",
      "tensor(17738.1523, grad_fn=<MseLossBackward0>)\n",
      "tensor(17553.7852, grad_fn=<MseLossBackward0>)\n",
      "tensor(17370.4766, grad_fn=<MseLossBackward0>)\n",
      "tensor(17187.5684, grad_fn=<MseLossBackward0>)\n",
      "tensor(17005.3223, grad_fn=<MseLossBackward0>)\n",
      "tensor(16823.4668, grad_fn=<MseLossBackward0>)\n",
      "tensor(16642.4102, grad_fn=<MseLossBackward0>)\n",
      "tensor(16462.0762, grad_fn=<MseLossBackward0>)\n",
      "tensor(16282.0400, grad_fn=<MseLossBackward0>)\n",
      "tensor(16102.9336, grad_fn=<MseLossBackward0>)\n",
      "tensor(15924.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(15746.7998, grad_fn=<MseLossBackward0>)\n",
      "tensor(15569.9844, grad_fn=<MseLossBackward0>)\n",
      "tensor(15393.6318, grad_fn=<MseLossBackward0>)\n",
      "tensor(15218.2266, grad_fn=<MseLossBackward0>)\n",
      "tensor(15043.8965, grad_fn=<MseLossBackward0>)\n",
      "tensor(14870.2031, grad_fn=<MseLossBackward0>)\n",
      "tensor(14697.4805, grad_fn=<MseLossBackward0>)\n",
      "tensor(14525.8096, grad_fn=<MseLossBackward0>)\n",
      "tensor(14354.9844, grad_fn=<MseLossBackward0>)\n",
      "tensor(14185.2451, grad_fn=<MseLossBackward0>)\n",
      "tensor(14016.3662, grad_fn=<MseLossBackward0>)\n",
      "tensor(13848.4902, grad_fn=<MseLossBackward0>)\n",
      "tensor(13681.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(13515.9111, grad_fn=<MseLossBackward0>)\n",
      "tensor(13351.2627, grad_fn=<MseLossBackward0>)\n",
      "tensor(13187.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(13025.3281, grad_fn=<MseLossBackward0>)\n",
      "tensor(12864.3467, grad_fn=<MseLossBackward0>)\n",
      "tensor(12704.1094, grad_fn=<MseLossBackward0>)\n",
      "tensor(12545.3574, grad_fn=<MseLossBackward0>)\n",
      "tensor(12387.7090, grad_fn=<MseLossBackward0>)\n",
      "tensor(12231.1104, grad_fn=<MseLossBackward0>)\n",
      "tensor(12076.1816, grad_fn=<MseLossBackward0>)\n",
      "tensor(11922.3164, grad_fn=<MseLossBackward0>)\n",
      "tensor(11769.7295, grad_fn=<MseLossBackward0>)\n",
      "tensor(11618.3271, grad_fn=<MseLossBackward0>)\n",
      "tensor(11468.5146, grad_fn=<MseLossBackward0>)\n",
      "tensor(11319.7920, grad_fn=<MseLossBackward0>)\n",
      "tensor(11172.5430, grad_fn=<MseLossBackward0>)\n",
      "tensor(11026.9277, grad_fn=<MseLossBackward0>)\n",
      "tensor(10882.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(10739.1543, grad_fn=<MseLossBackward0>)\n",
      "tensor(10597.4648, grad_fn=<MseLossBackward0>)\n",
      "tensor(10457.1396, grad_fn=<MseLossBackward0>)\n",
      "tensor(10318.1289, grad_fn=<MseLossBackward0>)\n",
      "tensor(10180.8223, grad_fn=<MseLossBackward0>)\n",
      "tensor(10044.9502, grad_fn=<MseLossBackward0>)\n",
      "tensor(9910.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(9777.5498, grad_fn=<MseLossBackward0>)\n",
      "tensor(9645.9473, grad_fn=<MseLossBackward0>)\n",
      "tensor(9516.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(9387.5654, grad_fn=<MseLossBackward0>)\n",
      "tensor(9260.4160, grad_fn=<MseLossBackward0>)\n",
      "tensor(9135.0410, grad_fn=<MseLossBackward0>)\n",
      "tensor(9010.9609, grad_fn=<MseLossBackward0>)\n",
      "tensor(8888.5732, grad_fn=<MseLossBackward0>)\n",
      "tensor(8767.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(8648.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(8530.4316, grad_fn=<MseLossBackward0>)\n",
      "tensor(8414.1025, grad_fn=<MseLossBackward0>)\n",
      "tensor(8299.3027, grad_fn=<MseLossBackward0>)\n",
      "tensor(8186.0820, grad_fn=<MseLossBackward0>)\n",
      "tensor(8074.3525, grad_fn=<MseLossBackward0>)\n",
      "tensor(7964.2388, grad_fn=<MseLossBackward0>)\n",
      "tensor(7855.6465, grad_fn=<MseLossBackward0>)\n",
      "tensor(7748.4038, grad_fn=<MseLossBackward0>)\n",
      "tensor(7642.8984, grad_fn=<MseLossBackward0>)\n",
      "tensor(7538.9302, grad_fn=<MseLossBackward0>)\n",
      "tensor(7436.3086, grad_fn=<MseLossBackward0>)\n",
      "tensor(7335.4312, grad_fn=<MseLossBackward0>)\n",
      "tensor(7235.9438, grad_fn=<MseLossBackward0>)\n",
      "tensor(7138.0347, grad_fn=<MseLossBackward0>)\n",
      "tensor(7041.4521, grad_fn=<MseLossBackward0>)\n",
      "tensor(6946.4707, grad_fn=<MseLossBackward0>)\n",
      "tensor(6852.9951, grad_fn=<MseLossBackward0>)\n",
      "tensor(6761.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(6670.4805, grad_fn=<MseLossBackward0>)\n",
      "tensor(6581.4775, grad_fn=<MseLossBackward0>)\n",
      "tensor(6493.8945, grad_fn=<MseLossBackward0>)\n",
      "tensor(6407.7041, grad_fn=<MseLossBackward0>)\n",
      "tensor(6322.9766, grad_fn=<MseLossBackward0>)\n",
      "tensor(6239.6299, grad_fn=<MseLossBackward0>)\n",
      "tensor(6157.7334, grad_fn=<MseLossBackward0>)\n",
      "tensor(6077.2871, grad_fn=<MseLossBackward0>)\n",
      "tensor(5998.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(5920.5122, grad_fn=<MseLossBackward0>)\n",
      "tensor(5843.9502, grad_fn=<MseLossBackward0>)\n",
      "tensor(5768.8911, grad_fn=<MseLossBackward0>)\n",
      "tensor(5695.1665, grad_fn=<MseLossBackward0>)\n",
      "tensor(5622.7495, grad_fn=<MseLossBackward0>)\n",
      "tensor(5551.6274, grad_fn=<MseLossBackward0>)\n",
      "tensor(5481.9009, grad_fn=<MseLossBackward0>)\n",
      "tensor(5413.2949, grad_fn=<MseLossBackward0>)\n",
      "tensor(5346.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(5279.9019, grad_fn=<MseLossBackward0>)\n",
      "tensor(5215.1235, grad_fn=<MseLossBackward0>)\n",
      "tensor(5151.3799, grad_fn=<MseLossBackward0>)\n",
      "tensor(5088.9302, grad_fn=<MseLossBackward0>)\n",
      "tensor(5027.5991, grad_fn=<MseLossBackward0>)\n",
      "tensor(4967.4458, grad_fn=<MseLossBackward0>)\n",
      "tensor(4908.4551, grad_fn=<MseLossBackward0>)\n",
      "tensor(4850.5762, grad_fn=<MseLossBackward0>)\n",
      "tensor(4793.7524, grad_fn=<MseLossBackward0>)\n",
      "tensor(4738.0425, grad_fn=<MseLossBackward0>)\n",
      "tensor(4683.4404, grad_fn=<MseLossBackward0>)\n",
      "tensor(4629.8818, grad_fn=<MseLossBackward0>)\n",
      "tensor(4577.2085, grad_fn=<MseLossBackward0>)\n",
      "tensor(4525.5435, grad_fn=<MseLossBackward0>)\n",
      "tensor(4474.9844, grad_fn=<MseLossBackward0>)\n",
      "tensor(4425.3857, grad_fn=<MseLossBackward0>)\n",
      "tensor(4376.6724, grad_fn=<MseLossBackward0>)\n",
      "tensor(4329.0054, grad_fn=<MseLossBackward0>)\n",
      "tensor(4282.0913, grad_fn=<MseLossBackward0>)\n",
      "tensor(4236.2451, grad_fn=<MseLossBackward0>)\n",
      "tensor(4191.0728, grad_fn=<MseLossBackward0>)\n",
      "tensor(4146.9878, grad_fn=<MseLossBackward0>)\n",
      "tensor(4103.6245, grad_fn=<MseLossBackward0>)\n",
      "tensor(4061.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(4019.4050, grad_fn=<MseLossBackward0>)\n",
      "tensor(3978.4583, grad_fn=<MseLossBackward0>)\n",
      "tensor(3938.2791, grad_fn=<MseLossBackward0>)\n",
      "tensor(3898.8850, grad_fn=<MseLossBackward0>)\n",
      "tensor(3860.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(3822.2654, grad_fn=<MseLossBackward0>)\n",
      "tensor(3785.1416, grad_fn=<MseLossBackward0>)\n",
      "tensor(3748.5664, grad_fn=<MseLossBackward0>)\n",
      "tensor(3712.6816, grad_fn=<MseLossBackward0>)\n",
      "tensor(3677.4592, grad_fn=<MseLossBackward0>)\n",
      "tensor(3642.9316, grad_fn=<MseLossBackward0>)\n",
      "tensor(3609.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(3575.6548, grad_fn=<MseLossBackward0>)\n",
      "tensor(3542.9902, grad_fn=<MseLossBackward0>)\n",
      "tensor(3510.7617, grad_fn=<MseLossBackward0>)\n",
      "tensor(3479.2292, grad_fn=<MseLossBackward0>)\n",
      "tensor(3448.2207, grad_fn=<MseLossBackward0>)\n",
      "tensor(3417.7527, grad_fn=<MseLossBackward0>)\n",
      "tensor(3387.8374, grad_fn=<MseLossBackward0>)\n",
      "tensor(3358.3433, grad_fn=<MseLossBackward0>)\n",
      "tensor(3329.4592, grad_fn=<MseLossBackward0>)\n",
      "tensor(3301.0173, grad_fn=<MseLossBackward0>)\n",
      "tensor(3273.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(3245.6052, grad_fn=<MseLossBackward0>)\n",
      "tensor(3218.5347, grad_fn=<MseLossBackward0>)\n",
      "tensor(3191.9316, grad_fn=<MseLossBackward0>)\n",
      "tensor(3165.7471, grad_fn=<MseLossBackward0>)\n",
      "tensor(3139.9661, grad_fn=<MseLossBackward0>)\n",
      "tensor(3114.6423, grad_fn=<MseLossBackward0>)\n",
      "tensor(3089.7290, grad_fn=<MseLossBackward0>)\n",
      "tensor(3065.1487, grad_fn=<MseLossBackward0>)\n",
      "tensor(3040.9468, grad_fn=<MseLossBackward0>)\n",
      "tensor(3017.2463, grad_fn=<MseLossBackward0>)\n",
      "tensor(2993.7388, grad_fn=<MseLossBackward0>)\n",
      "tensor(2970.6240, grad_fn=<MseLossBackward0>)\n",
      "tensor(2947.8940, grad_fn=<MseLossBackward0>)\n",
      "tensor(2925.5247, grad_fn=<MseLossBackward0>)\n",
      "tensor(2903.3906, grad_fn=<MseLossBackward0>)\n",
      "tensor(2881.5854, grad_fn=<MseLossBackward0>)\n",
      "tensor(2860.2063, grad_fn=<MseLossBackward0>)\n",
      "tensor(2839.0166, grad_fn=<MseLossBackward0>)\n",
      "tensor(2818.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(2797.5630, grad_fn=<MseLossBackward0>)\n",
      "tensor(2777.3076, grad_fn=<MseLossBackward0>)\n",
      "tensor(2757.3359, grad_fn=<MseLossBackward0>)\n",
      "tensor(2737.5508, grad_fn=<MseLossBackward0>)\n",
      "tensor(2718.0674, grad_fn=<MseLossBackward0>)\n",
      "tensor(2698.8242, grad_fn=<MseLossBackward0>)\n",
      "tensor(2679.9470, grad_fn=<MseLossBackward0>)\n",
      "tensor(2661.1616, grad_fn=<MseLossBackward0>)\n",
      "tensor(2642.7607, grad_fn=<MseLossBackward0>)\n",
      "tensor(2624.4810, grad_fn=<MseLossBackward0>)\n",
      "tensor(2606.5535, grad_fn=<MseLossBackward0>)\n",
      "tensor(2588.7446, grad_fn=<MseLossBackward0>)\n",
      "tensor(2571.2014, grad_fn=<MseLossBackward0>)\n",
      "tensor(2553.8176, grad_fn=<MseLossBackward0>)\n",
      "tensor(2536.7866, grad_fn=<MseLossBackward0>)\n",
      "tensor(2519.8215, grad_fn=<MseLossBackward0>)\n",
      "tensor(2503.1440, grad_fn=<MseLossBackward0>)\n",
      "tensor(2486.6194, grad_fn=<MseLossBackward0>)\n",
      "tensor(2470.3701, grad_fn=<MseLossBackward0>)\n",
      "tensor(2454.1873, grad_fn=<MseLossBackward0>)\n",
      "tensor(2438.3396, grad_fn=<MseLossBackward0>)\n",
      "tensor(2422.6111, grad_fn=<MseLossBackward0>)\n",
      "tensor(2407.0486, grad_fn=<MseLossBackward0>)\n",
      "tensor(2391.7139, grad_fn=<MseLossBackward0>)\n",
      "tensor(2376.5588, grad_fn=<MseLossBackward0>)\n",
      "tensor(2361.5510, grad_fn=<MseLossBackward0>)\n",
      "tensor(2346.7407, grad_fn=<MseLossBackward0>)\n",
      "tensor(2332.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(2317.5835, grad_fn=<MseLossBackward0>)\n",
      "tensor(2303.2468, grad_fn=<MseLossBackward0>)\n",
      "tensor(2289.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(2275.1570, grad_fn=<MseLossBackward0>)\n",
      "tensor(2261.3276, grad_fn=<MseLossBackward0>)\n",
      "tensor(2247.7026, grad_fn=<MseLossBackward0>)\n",
      "tensor(2234.1528, grad_fn=<MseLossBackward0>)\n",
      "tensor(2220.7664, grad_fn=<MseLossBackward0>)\n",
      "tensor(2207.5518, grad_fn=<MseLossBackward0>)\n",
      "tensor(2194.4976, grad_fn=<MseLossBackward0>)\n",
      "tensor(2181.6265, grad_fn=<MseLossBackward0>)\n",
      "tensor(2168.8806, grad_fn=<MseLossBackward0>)\n",
      "tensor(2156.1982, grad_fn=<MseLossBackward0>)\n",
      "tensor(2143.7778, grad_fn=<MseLossBackward0>)\n",
      "tensor(2131.4109, grad_fn=<MseLossBackward0>)\n",
      "tensor(2119.2180, grad_fn=<MseLossBackward0>)\n",
      "tensor(2107.1653, grad_fn=<MseLossBackward0>)\n",
      "tensor(2095.3169, grad_fn=<MseLossBackward0>)\n",
      "tensor(2083.4856, grad_fn=<MseLossBackward0>)\n",
      "tensor(2071.8638, grad_fn=<MseLossBackward0>)\n",
      "tensor(2060.3577, grad_fn=<MseLossBackward0>)\n",
      "tensor(2048.9377, grad_fn=<MseLossBackward0>)\n",
      "tensor(2037.7084, grad_fn=<MseLossBackward0>)\n",
      "tensor(2026.5544, grad_fn=<MseLossBackward0>)\n",
      "tensor(2015.5706, grad_fn=<MseLossBackward0>)\n",
      "tensor(2004.6812, grad_fn=<MseLossBackward0>)\n",
      "tensor(1994.0038, grad_fn=<MseLossBackward0>)\n",
      "tensor(1983.3384, grad_fn=<MseLossBackward0>)\n",
      "tensor(1972.8268, grad_fn=<MseLossBackward0>)\n",
      "tensor(1962.5159, grad_fn=<MseLossBackward0>)\n",
      "tensor(1952.2025, grad_fn=<MseLossBackward0>)\n",
      "tensor(1942.0681, grad_fn=<MseLossBackward0>)\n",
      "tensor(1932.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(1922.1492, grad_fn=<MseLossBackward0>)\n",
      "tensor(1912.3927, grad_fn=<MseLossBackward0>)\n",
      "tensor(1902.7158, grad_fn=<MseLossBackward0>)\n",
      "tensor(1893.1606, grad_fn=<MseLossBackward0>)\n",
      "tensor(1883.7194, grad_fn=<MseLossBackward0>)\n",
      "tensor(1874.4460, grad_fn=<MseLossBackward0>)\n",
      "tensor(1865.2377, grad_fn=<MseLossBackward0>)\n",
      "tensor(1856.1506, grad_fn=<MseLossBackward0>)\n",
      "tensor(1847.1089, grad_fn=<MseLossBackward0>)\n",
      "tensor(1838.2148, grad_fn=<MseLossBackward0>)\n",
      "tensor(1829.5111, grad_fn=<MseLossBackward0>)\n",
      "tensor(1820.7924, grad_fn=<MseLossBackward0>)\n",
      "tensor(1812.2339, grad_fn=<MseLossBackward0>)\n",
      "tensor(1803.7783, grad_fn=<MseLossBackward0>)\n",
      "tensor(1795.4580, grad_fn=<MseLossBackward0>)\n",
      "tensor(1787.2050, grad_fn=<MseLossBackward0>)\n",
      "tensor(1779.0341, grad_fn=<MseLossBackward0>)\n",
      "tensor(1771.0177, grad_fn=<MseLossBackward0>)\n",
      "tensor(1763.0675, grad_fn=<MseLossBackward0>)\n",
      "tensor(1755.2153, grad_fn=<MseLossBackward0>)\n",
      "tensor(1747.4393, grad_fn=<MseLossBackward0>)\n",
      "tensor(1739.8473, grad_fn=<MseLossBackward0>)\n",
      "tensor(1732.3149, grad_fn=<MseLossBackward0>)\n",
      "tensor(1724.8334, grad_fn=<MseLossBackward0>)\n",
      "tensor(1717.4138, grad_fn=<MseLossBackward0>)\n",
      "tensor(1710.1627, grad_fn=<MseLossBackward0>)\n",
      "tensor(1702.9923, grad_fn=<MseLossBackward0>)\n",
      "tensor(1695.9558, grad_fn=<MseLossBackward0>)\n",
      "tensor(1688.9723, grad_fn=<MseLossBackward0>)\n",
      "tensor(1682.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1675.2827, grad_fn=<MseLossBackward0>)\n",
      "tensor(1668.5605, grad_fn=<MseLossBackward0>)\n",
      "tensor(1661.9235, grad_fn=<MseLossBackward0>)\n",
      "tensor(1655.4301, grad_fn=<MseLossBackward0>)\n",
      "tensor(1648.9148, grad_fn=<MseLossBackward0>)\n",
      "tensor(1642.6078, grad_fn=<MseLossBackward0>)\n",
      "tensor(1636.3440, grad_fn=<MseLossBackward0>)\n",
      "tensor(1630.1144, grad_fn=<MseLossBackward0>)\n",
      "tensor(1624.0072, grad_fn=<MseLossBackward0>)\n",
      "tensor(1617.9832, grad_fn=<MseLossBackward0>)\n",
      "tensor(1612.0721, grad_fn=<MseLossBackward0>)\n",
      "tensor(1606.1757, grad_fn=<MseLossBackward0>)\n",
      "tensor(1600.4250, grad_fn=<MseLossBackward0>)\n",
      "tensor(1594.6838, grad_fn=<MseLossBackward0>)\n",
      "tensor(1589.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(1583.5588, grad_fn=<MseLossBackward0>)\n",
      "tensor(1578.0461, grad_fn=<MseLossBackward0>)\n",
      "tensor(1572.6953, grad_fn=<MseLossBackward0>)\n",
      "tensor(1567.4320, grad_fn=<MseLossBackward0>)\n",
      "tensor(1562.1541, grad_fn=<MseLossBackward0>)\n",
      "tensor(1557.0200, grad_fn=<MseLossBackward0>)\n",
      "tensor(1551.8762, grad_fn=<MseLossBackward0>)\n",
      "tensor(1546.8646, grad_fn=<MseLossBackward0>)\n",
      "tensor(1541.9694, grad_fn=<MseLossBackward0>)\n",
      "tensor(1537.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(1532.2706, grad_fn=<MseLossBackward0>)\n",
      "tensor(1527.5470, grad_fn=<MseLossBackward0>)\n",
      "tensor(1522.9548, grad_fn=<MseLossBackward0>)\n",
      "tensor(1518.3015, grad_fn=<MseLossBackward0>)\n",
      "tensor(1513.7260, grad_fn=<MseLossBackward0>)\n",
      "tensor(1509.3210, grad_fn=<MseLossBackward0>)\n",
      "tensor(1504.8873, grad_fn=<MseLossBackward0>)\n",
      "tensor(1500.5770, grad_fn=<MseLossBackward0>)\n",
      "tensor(1496.3185, grad_fn=<MseLossBackward0>)\n",
      "tensor(1492.1490, grad_fn=<MseLossBackward0>)\n",
      "tensor(1488.0042, grad_fn=<MseLossBackward0>)\n",
      "tensor(1483.9823, grad_fn=<MseLossBackward0>)\n",
      "tensor(1479.8843, grad_fn=<MseLossBackward0>)\n",
      "tensor(1475.9667, grad_fn=<MseLossBackward0>)\n",
      "tensor(1472.0803, grad_fn=<MseLossBackward0>)\n",
      "tensor(1468.3290, grad_fn=<MseLossBackward0>)\n",
      "tensor(1464.4805, grad_fn=<MseLossBackward0>)\n",
      "tensor(1460.8157, grad_fn=<MseLossBackward0>)\n",
      "tensor(1457.1356, grad_fn=<MseLossBackward0>)\n",
      "tensor(1453.5663, grad_fn=<MseLossBackward0>)\n",
      "tensor(1449.9963, grad_fn=<MseLossBackward0>)\n",
      "tensor(1446.5247, grad_fn=<MseLossBackward0>)\n",
      "tensor(1443.0754, grad_fn=<MseLossBackward0>)\n",
      "tensor(1439.7476, grad_fn=<MseLossBackward0>)\n",
      "tensor(1436.4285, grad_fn=<MseLossBackward0>)\n",
      "tensor(1433.1504, grad_fn=<MseLossBackward0>)\n",
      "tensor(1429.9425, grad_fn=<MseLossBackward0>)\n",
      "tensor(1426.7732, grad_fn=<MseLossBackward0>)\n",
      "tensor(1423.6890, grad_fn=<MseLossBackward0>)\n",
      "tensor(1420.5868, grad_fn=<MseLossBackward0>)\n",
      "tensor(1417.6036, grad_fn=<MseLossBackward0>)\n",
      "tensor(1414.6740, grad_fn=<MseLossBackward0>)\n",
      "tensor(1411.6857, grad_fn=<MseLossBackward0>)\n",
      "tensor(1408.8625, grad_fn=<MseLossBackward0>)\n",
      "tensor(1406.0383, grad_fn=<MseLossBackward0>)\n",
      "tensor(1403.2543, grad_fn=<MseLossBackward0>)\n",
      "tensor(1400.5972, grad_fn=<MseLossBackward0>)\n",
      "tensor(1397.8956, grad_fn=<MseLossBackward0>)\n",
      "tensor(1395.2097, grad_fn=<MseLossBackward0>)\n",
      "tensor(1392.6887, grad_fn=<MseLossBackward0>)\n",
      "tensor(1390.0829, grad_fn=<MseLossBackward0>)\n",
      "tensor(1387.5662, grad_fn=<MseLossBackward0>)\n",
      "tensor(1385.0792, grad_fn=<MseLossBackward0>)\n",
      "tensor(1382.7395, grad_fn=<MseLossBackward0>)\n",
      "tensor(1380.3751, grad_fn=<MseLossBackward0>)\n",
      "tensor(1378.0082, grad_fn=<MseLossBackward0>)\n",
      "tensor(1375.7496, grad_fn=<MseLossBackward0>)\n",
      "tensor(1373.4180, grad_fn=<MseLossBackward0>)\n",
      "tensor(1371.2493, grad_fn=<MseLossBackward0>)\n",
      "tensor(1369.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(1366.9258, grad_fn=<MseLossBackward0>)\n",
      "tensor(1364.8423, grad_fn=<MseLossBackward0>)\n",
      "tensor(1362.7550, grad_fn=<MseLossBackward0>)\n",
      "tensor(1360.7227, grad_fn=<MseLossBackward0>)\n",
      "tensor(1358.7275, grad_fn=<MseLossBackward0>)\n",
      "tensor(1356.7407, grad_fn=<MseLossBackward0>)\n",
      "tensor(1354.8394, grad_fn=<MseLossBackward0>)\n",
      "tensor(1352.9474, grad_fn=<MseLossBackward0>)\n",
      "tensor(1351.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(1349.2703, grad_fn=<MseLossBackward0>)\n",
      "tensor(1347.4684, grad_fn=<MseLossBackward0>)\n",
      "tensor(1345.7277, grad_fn=<MseLossBackward0>)\n",
      "tensor(1343.9866, grad_fn=<MseLossBackward0>)\n",
      "tensor(1342.2549, grad_fn=<MseLossBackward0>)\n",
      "tensor(1340.6726, grad_fn=<MseLossBackward0>)\n",
      "tensor(1339.0026, grad_fn=<MseLossBackward0>)\n",
      "tensor(1337.3942, grad_fn=<MseLossBackward0>)\n",
      "tensor(1335.8796, grad_fn=<MseLossBackward0>)\n",
      "tensor(1334.2461, grad_fn=<MseLossBackward0>)\n",
      "tensor(1332.8003, grad_fn=<MseLossBackward0>)\n",
      "tensor(1331.2974, grad_fn=<MseLossBackward0>)\n",
      "tensor(1329.8038, grad_fn=<MseLossBackward0>)\n",
      "tensor(1328.3732, grad_fn=<MseLossBackward0>)\n",
      "tensor(1326.9650, grad_fn=<MseLossBackward0>)\n",
      "tensor(1325.5945, grad_fn=<MseLossBackward0>)\n",
      "tensor(1324.2782, grad_fn=<MseLossBackward0>)\n",
      "tensor(1322.9154, grad_fn=<MseLossBackward0>)\n",
      "tensor(1321.6042, grad_fn=<MseLossBackward0>)\n",
      "tensor(1320.2966, grad_fn=<MseLossBackward0>)\n",
      "tensor(1319.0516, grad_fn=<MseLossBackward0>)\n",
      "tensor(1317.8785, grad_fn=<MseLossBackward0>)\n",
      "tensor(1316.6163, grad_fn=<MseLossBackward0>)\n",
      "tensor(1315.4611, grad_fn=<MseLossBackward0>)\n",
      "tensor(1314.3076, grad_fn=<MseLossBackward0>)\n",
      "tensor(1313.1621, grad_fn=<MseLossBackward0>)\n",
      "tensor(1311.9983, grad_fn=<MseLossBackward0>)\n",
      "tensor(1310.9449, grad_fn=<MseLossBackward0>)\n",
      "tensor(1309.8728, grad_fn=<MseLossBackward0>)\n",
      "tensor(1308.8561, grad_fn=<MseLossBackward0>)\n",
      "tensor(1307.7643, grad_fn=<MseLossBackward0>)\n",
      "tensor(1306.8226, grad_fn=<MseLossBackward0>)\n",
      "tensor(1305.7520, grad_fn=<MseLossBackward0>)\n",
      "tensor(1304.8145, grad_fn=<MseLossBackward0>)\n",
      "tensor(1303.8964, grad_fn=<MseLossBackward0>)\n",
      "tensor(1302.9174, grad_fn=<MseLossBackward0>)\n",
      "tensor(1301.9810, grad_fn=<MseLossBackward0>)\n",
      "tensor(1301.1177, grad_fn=<MseLossBackward0>)\n",
      "tensor(1300.2600, grad_fn=<MseLossBackward0>)\n",
      "tensor(1299.3873, grad_fn=<MseLossBackward0>)\n",
      "tensor(1298.4995, grad_fn=<MseLossBackward0>)\n",
      "tensor(1297.6934, grad_fn=<MseLossBackward0>)\n",
      "tensor(1296.9253, grad_fn=<MseLossBackward0>)\n",
      "tensor(1296.1294, grad_fn=<MseLossBackward0>)\n",
      "tensor(1295.3339, grad_fn=<MseLossBackward0>)\n",
      "tensor(1294.6226, grad_fn=<MseLossBackward0>)\n",
      "tensor(1293.8545, grad_fn=<MseLossBackward0>)\n",
      "tensor(1293.0956, grad_fn=<MseLossBackward0>)\n",
      "tensor(1292.3926, grad_fn=<MseLossBackward0>)\n",
      "tensor(1291.6635, grad_fn=<MseLossBackward0>)\n",
      "tensor(1290.9790, grad_fn=<MseLossBackward0>)\n",
      "tensor(1290.2791, grad_fn=<MseLossBackward0>)\n",
      "tensor(1289.6460, grad_fn=<MseLossBackward0>)\n",
      "tensor(1288.9846, grad_fn=<MseLossBackward0>)\n",
      "tensor(1288.4114, grad_fn=<MseLossBackward0>)\n",
      "tensor(1287.7701, grad_fn=<MseLossBackward0>)\n",
      "tensor(1287.1578, grad_fn=<MseLossBackward0>)\n",
      "tensor(1286.5854, grad_fn=<MseLossBackward0>)\n",
      "tensor(1285.9576, grad_fn=<MseLossBackward0>)\n",
      "tensor(1285.4288, grad_fn=<MseLossBackward0>)\n",
      "tensor(1284.8795, grad_fn=<MseLossBackward0>)\n",
      "tensor(1284.3029, grad_fn=<MseLossBackward0>)\n",
      "tensor(1283.7205, grad_fn=<MseLossBackward0>)\n",
      "tensor(1283.2499, grad_fn=<MseLossBackward0>)\n",
      "tensor(1282.7759, grad_fn=<MseLossBackward0>)\n",
      "tensor(1282.2352, grad_fn=<MseLossBackward0>)\n",
      "tensor(1281.7546, grad_fn=<MseLossBackward0>)\n",
      "tensor(1281.2845, grad_fn=<MseLossBackward0>)\n",
      "tensor(1280.8174, grad_fn=<MseLossBackward0>)\n",
      "tensor(1280.3082, grad_fn=<MseLossBackward0>)\n",
      "tensor(1279.9198, grad_fn=<MseLossBackward0>)\n",
      "tensor(1279.4993, grad_fn=<MseLossBackward0>)\n",
      "tensor(1279.0490, grad_fn=<MseLossBackward0>)\n",
      "tensor(1278.6482, grad_fn=<MseLossBackward0>)\n",
      "tensor(1278.2321, grad_fn=<MseLossBackward0>)\n",
      "tensor(1277.8617, grad_fn=<MseLossBackward0>)\n",
      "tensor(1277.4432, grad_fn=<MseLossBackward0>)\n",
      "tensor(1277.0968, grad_fn=<MseLossBackward0>)\n",
      "tensor(1276.6683, grad_fn=<MseLossBackward0>)\n",
      "tensor(1276.3517, grad_fn=<MseLossBackward0>)\n",
      "tensor(1275.9211, grad_fn=<MseLossBackward0>)\n",
      "tensor(1275.6139, grad_fn=<MseLossBackward0>)\n",
      "tensor(1275.2147, grad_fn=<MseLossBackward0>)\n",
      "tensor(1274.9153, grad_fn=<MseLossBackward0>)\n",
      "tensor(1274.5978, grad_fn=<MseLossBackward0>)\n",
      "tensor(1274.2860, grad_fn=<MseLossBackward0>)\n",
      "tensor(1273.9266, grad_fn=<MseLossBackward0>)\n",
      "tensor(1273.6488, grad_fn=<MseLossBackward0>)\n",
      "tensor(1273.3702, grad_fn=<MseLossBackward0>)\n",
      "tensor(1273.0535, grad_fn=<MseLossBackward0>)\n",
      "tensor(1272.8171, grad_fn=<MseLossBackward0>)\n",
      "tensor(1272.4694, grad_fn=<MseLossBackward0>)\n",
      "tensor(1272.2163, grad_fn=<MseLossBackward0>)\n",
      "tensor(1271.9363, grad_fn=<MseLossBackward0>)\n",
      "tensor(1271.6692, grad_fn=<MseLossBackward0>)\n",
      "tensor(1271.4150, grad_fn=<MseLossBackward0>)\n",
      "tensor(1271.2239, grad_fn=<MseLossBackward0>)\n",
      "tensor(1270.9476, grad_fn=<MseLossBackward0>)\n",
      "tensor(1270.7288, grad_fn=<MseLossBackward0>)\n",
      "tensor(1270.4958, grad_fn=<MseLossBackward0>)\n",
      "tensor(1270.2834, grad_fn=<MseLossBackward0>)\n",
      "tensor(1270.0154, grad_fn=<MseLossBackward0>)\n",
      "tensor(1269.8206, grad_fn=<MseLossBackward0>)\n",
      "tensor(1269.5774, grad_fn=<MseLossBackward0>)\n",
      "tensor(1269.3641, grad_fn=<MseLossBackward0>)\n",
      "tensor(1269.2552, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.9645, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.7999, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.6414, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.4316, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.2543, grad_fn=<MseLossBackward0>)\n",
      "tensor(1268.0686, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.9502, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.7218, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.6005, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.4215, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.2551, grad_fn=<MseLossBackward0>)\n",
      "tensor(1267.1266, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.9734, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.8190, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.6879, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.5610, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.4008, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.3058, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.1560, grad_fn=<MseLossBackward0>)\n",
      "tensor(1266.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.8979, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.7797, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.6785, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.5647, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.4412, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.3420, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.2952, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.1720, grad_fn=<MseLossBackward0>)\n",
      "tensor(1265.0447, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.9930, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.8195, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.7559, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.6450, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.5863, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.5145, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.4246, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.3334, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.2750, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.1274, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.0698, grad_fn=<MseLossBackward0>)\n",
      "tensor(1264.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.9281, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.8817, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.8124, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.7822, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.7479, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.6273, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.5746, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.5127, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.4408, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.4058, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.3005, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.2455, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.1825, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.1632, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.1119, grad_fn=<MseLossBackward0>)\n",
      "tensor(1263.0879, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.9879, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.9364, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.9442, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.8612, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.8712, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.7983, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.7451, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.7258, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.6324, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.6625, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.5852, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.5369, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.5109, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.4922, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.4679, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.4365, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.3884, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.3933, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.3439, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.2850, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.3311, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.2555, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.2291, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.2007, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.1761, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.1335, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.1382, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.1433, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.0831, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.0981, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.0841, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9950, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9958, grad_fn=<MseLossBackward0>)\n",
      "tensor(1262.0089, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9137, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9069, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9266, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9531, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8933, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.9147, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8646, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8352, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8363, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7905, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8563, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.8281, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7462, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7688, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7843, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6882, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7186, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7709, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6447, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6899, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6930, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.7202, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6877, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6666, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6771, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6558, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6240, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6050, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6555, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5747, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6044, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5521, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5863, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.6301, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5396, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5830, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5208, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5608, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4657, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5131, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5361, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5231, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4813, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5303, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4764, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5068, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4329, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5035, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4429, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4376, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.5074, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4723, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4209, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4078, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4103, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4530, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3925, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4209, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4215, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4603, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3519, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3890, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4292, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4224, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4408, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4454, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4401, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3728, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3654, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3922, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3915, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4186, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4207, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4032, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3660, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3287, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3455, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3925, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3821, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3678, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3224, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4221, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3607, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4255, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3212, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3373, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3470, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3929, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3566, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3574, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3431, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3396, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4069, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3318, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3553, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2845, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3682, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3390, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3672, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3035, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3733, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3765, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3813, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3400, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3005, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3744, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3044, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3083, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3380, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3080, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3937, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3702, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3707, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4103, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3254, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3484, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3920, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4132, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3699, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4078, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2400, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2482, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3004, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3452, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3085, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3210, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3326, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3827, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2620, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3402, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3480, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3644, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2498, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3359, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2910, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3131, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2358, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2820, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3652, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3608, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3042, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3676, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3109, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3690, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3617, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3279, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3528, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3741, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3595, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3447, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3995, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3151, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2483, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3262, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3335, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2930, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3862, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3861, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3442, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2964, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3292, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2987, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3353, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2810, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3258, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3000, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3378, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3073, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4091, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3165, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2931, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2971, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2980, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3644, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2710, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2911, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3641, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3036, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2828, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3032, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3125, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2742, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3578, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3407, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3601, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2865, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3134, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2491, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3365, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3843, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2985, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3993, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3097, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4056, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3370, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2753, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2756, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4139, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3304, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2260, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3927, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2264, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3328, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3646, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2946, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3453, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3389, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3684, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3040, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3008, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3872, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2571, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3158, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3430, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3441, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2725, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2770, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3722, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3745, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2847, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2979, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3363, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3037, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3458, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3879, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3029, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3402, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2559, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3319, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3473, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2629, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3127, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4753, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3286, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2546, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3086, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2941, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3140, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3630, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3450, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3110, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3546, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2585, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3002, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3185, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3258, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2545, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3292, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3265, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.4019, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3236, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3381, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3274, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2896, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2603, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3705, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2323, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3196, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2504, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2269, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3407, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2711, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.2513, grad_fn=<MseLossBackward0>)\n",
      "tensor(1261.3373, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d_model = 64\n",
    "hidden_channels = 64\n",
    "d_target = 15\n",
    "vocab_size = len(tokenDict)\n",
    "\n",
    "\n",
    "model = TransformerNetwork(hidden_channels,d_target,vocab_size,maxTokenLength) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train(data_in, targets):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data_in)\n",
    "      loss = criterion(out, targets)\n",
    "\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "      return loss\n",
    "\n",
    "\n",
    "testTensors = encodedTensors[:100]\n",
    "testTargets = y[:100]\n",
    "\n",
    "for epoch in range(1000):\n",
    "      loss = train(testTensors,testTargets)\n",
    "      print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
